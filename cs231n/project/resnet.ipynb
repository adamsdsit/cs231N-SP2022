{"cells":[{"cell_type":"code","execution_count":1,"id":"b3161578","metadata":{"id":"b3161578","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654150293055,"user_tz":180,"elapsed":20888,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}},"outputId":"9ea4dafb-135a-4e27-b03e-1dc17e717339"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/cs231n/project\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n","FOLDERNAME = 'cs231n/project/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","%cd /content/drive/My\\ Drive/$FOLDERNAME\n"]},{"cell_type":"markdown","source":["# Initial Setup"],"metadata":{"id":"w84bcHaismK6"},"id":"w84bcHaismK6"},{"cell_type":"code","source":["# As usual, a bit of setup\n","!ls\n","%cd code\n","\n","import utils\n","import tensorflow as tf\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.initializers import RandomUniform, glorot_uniform, constant, identity\n","from PIL import Image\n","import os\n","import pandas as pd\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","%cd ..\n","!ls"],"metadata":{"id":"iBoGwIJ-a7Qi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654150301652,"user_tz":180,"elapsed":4980,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}},"outputId":"746b5bbe-048b-4469-bc9a-d7d386b80141"},"id":"iBoGwIJ-a7Qi","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["cnn_vgg_19.ipynb\tcnn_vgg_19_old.ipynb  resnet_old_3.ipynb\n","cnn_vgg_19_old_2.ipynb\tcode\t\t      resnet_old_4.ipynb\n","cnn_vgg_19_old_3.ipynb\tresent_old_2.ipynb    resnet_old_5.ipynb\n","cnn_vgg_19_old_4.ipynb\tresnet.ipynb\t      resnet_old.ipynb\n","/content/drive/My Drive/cs231n/project/code\n","/content/drive/My Drive/cs231n/project\n","cnn_vgg_19.ipynb\tcnn_vgg_19_old.ipynb  resnet_old_3.ipynb\n","cnn_vgg_19_old_2.ipynb\tcode\t\t      resnet_old_4.ipynb\n","cnn_vgg_19_old_3.ipynb\tresent_old_2.ipynb    resnet_old_5.ipynb\n","cnn_vgg_19_old_4.ipynb\tresnet.ipynb\t      resnet_old.ipynb\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"kdaUXvbfywnt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654150306644,"user_tz":180,"elapsed":633,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}},"outputId":"6a84d9da-937c-4f4b-d75a-62860b7a4f0a"},"id":"kdaUXvbfywnt","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jun  2 06:11:49 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ryErIThRyqal","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654150311041,"user_tz":180,"elapsed":529,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}},"outputId":"e45194d2-c637-410b-9aad-7b1fce431aba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 54.8 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"id":"ryErIThRyqal"},{"cell_type":"markdown","source":["# Identity Block"],"metadata":{"id":"EstEG_2GbNI1"},"id":"EstEG_2GbNI1"},{"cell_type":"code","source":["def identity_block(X, f, filters, training=True, initializer=RandomUniform):\n","    \"\"\"\n","    Implementation of the identity block as defined in Figure 4\n","    \n","    Arguments:\n","    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    f -- integer, specifying the shape of the middle CONV's window for the main path\n","    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n","    training -- True: Behave in training mode\n","                False: Behave in inference mode\n","    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n","    \n","    Returns:\n","    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n","    \"\"\"\n","    \n","    # Retrieve Filters\n","    F1, F2, F3 = filters\n","    \n","    # Save the input value. You'll need this later to add back to the main path. \n","    X_shortcut = X\n","    \n","    # First component of main path\n","    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n","    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n","    X = Activation('relu')(X)\n","    \n","    ### START CODE HERE\n","    ## Second component of main path (≈3 lines)\n","    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n","    X = BatchNormalization(axis = 3)(X, training = training)\n","    X = Activation('relu')(X)\n","\n","    ## Third component of main path (≈2 lines)\n","    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n","    X = BatchNormalization(axis = 3)(X, training = training) \n","    \n","    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n","    X = Add()([X, X_shortcut])\n","    X = Activation('relu')(X) \n","    ### END CODE HERE\n","\n","    return X"],"metadata":{"id":"J3DBljeGbQsz","executionInfo":{"status":"ok","timestamp":1654150316370,"user_tz":180,"elapsed":528,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}}},"id":"J3DBljeGbQsz","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Convolutional Block"],"metadata":{"id":"3ae5yg5qbbQG"},"id":"3ae5yg5qbbQG"},{"cell_type":"code","source":["def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n","    \"\"\"\n","    Implementation of the convolutional block as defined in Figure 4\n","    \n","    Arguments:\n","    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    f -- integer, specifying the shape of the middle CONV's window for the main path\n","    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n","    s -- Integer, specifying the stride to be used\n","    training -- True: Behave in training mode\n","                False: Behave in inference mode\n","    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n","                   also called Xavier uniform initializer.\n","    \n","    Returns:\n","    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n","    \"\"\"\n","    \n","    # Retrieve Filters\n","    F1, F2, F3 = filters\n","    \n","    # Save the input value\n","    X_shortcut = X\n","\n","    ##### MAIN PATH #####\n","    \n","    # First component of main path glorot_uniform(seed=0)\n","    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n","    X = BatchNormalization(axis = 3)(X, training=training)\n","    X = Activation('relu')(X)\n","\n","    ### START CODE HERE\n","    \n","    ## Second component of main path (≈3 lines)\n","    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis = 3)(X, training=training) \n","    X = Activation('relu')(X) \n","\n","    ## Third component of main path (≈2 lines)\n","    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis = 3)(X, training=training)  \n","    \n","    ##### SHORTCUT PATH ##### (≈2 lines)\n","    X_shortcut = Conv2D(filters=F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n","    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n","    \n","    ### END CODE HERE\n","\n","    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n","    X = Add()([X, X_shortcut])\n","    X = Activation('relu')(X)\n","    \n","    return X"],"metadata":{"id":"TM2AEbCNbfGl","executionInfo":{"status":"ok","timestamp":1654150321182,"user_tz":180,"elapsed":329,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}}},"id":"TM2AEbCNbfGl","execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Create Resnet-152"],"metadata":{"id":"lotmsznEsg5U"},"id":"lotmsznEsg5U"},{"cell_type":"code","execution_count":7,"id":"cd40e03b","metadata":{"tags":["pdf-ignore"],"id":"cd40e03b","executionInfo":{"status":"ok","timestamp":1654150325022,"user_tz":180,"elapsed":540,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}}},"outputs":[],"source":["def ResNet152(input_shape = (224 ,224, 3), classes = 7):\n","    \"\"\"\n","    Stage-wise implementation of the architecture of the popular ResNet50:\n","    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n","    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n","\n","    Arguments:\n","    input_shape -- shape of the images of the dataset\n","    classes -- integer, number of classes\n","\n","    Returns:\n","    model -- a Model() instance in Keras\n","    \"\"\"\n","    \n","    # Define the input as a tensor with shape input_shape\n","    X_input = Input(input_shape)\n","\n","    # Zero-Padding\n","    X = ZeroPadding2D((3, 3))(X_input)\n","    \n","    # Stage 1\n","    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis = 3)(X)\n","    X = Activation('relu')(X)\n","    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n","\n","    # Stage 2\n","    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n","    X = identity_block(X, 3, [64, 64, 256])\n","    X = identity_block(X, 3, [64, 64, 256])\n","    \n","    ## Stage 3 (≈4 lines)\n","    X = convolutional_block(X, f=3, filters = [128, 128, 512], s=2) \n","    for i in range(7):\n","      X = identity_block(X, 3, [128, 128, 512]) \n","      #X = identity_block(X, 3, [128, 128, 512])\n","      #X = identity_block(X, 3, [128, 128, 512]) \n","    \n","    ## Stage 4 (≈6 lines)\n","    X = convolutional_block(X, f=3, filters = [256, 256, 1024], s=2) \n","    for i in range(35):\n","      X = identity_block(X, 3, [256, 256, 1024]) \n","      #X = identity_block(X, 3, [256, 256, 1024]) \n","      #X = identity_block(X, 3, [256, 256, 1024]) \n","      #X = identity_block(X, 3, [256, 256, 1024]) \n","      #X = identity_block(X, 3, [256, 256, 1024]) \n","\n","    ## Stage 5 (≈3 lines)\n","    X = convolutional_block(X, f=3, filters = [512, 512, 2048], s=2) \n","    X = identity_block(X, 3, [512, 512, 2048]) \n","    X = identity_block(X, 3, [512, 512, 2048]) \n","\n","    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n","    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n","\n","    # output layer\n","    X = Flatten()(X)\n","    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n","    \n","    # Create model\n","    model = Model(inputs = X_input, outputs = X)\n","\n","    return model"]},{"cell_type":"markdown","source":["# Testing the mean values"],"metadata":{"id":"gJ6Nryd_1NrE"},"id":"gJ6Nryd_1NrE"},{"cell_type":"code","source":["img1 = np.ones((1,224,224,3))\n","img2 = np.zeros((1,224,224,3))\n","img3 = np.ones((1,224,224,3))\n","img4 = np.ones((1,224,224,3))\n","values = np.vstack([img1, img2, img3, img4])\n","N = values.shape[0]\n","means = np.sum(values, axis=0) / N\n","mean = np.mean(values)\n","print((img2 - means)[0].shape)\n","print(mean)"],"metadata":{"id":"Ws3CDGH7xQCl"},"id":"Ws3CDGH7xQCl","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load the dataset"],"metadata":{"id":"UvOytyfIscwV"},"id":"UvOytyfIscwV"},{"cell_type":"code","execution_count":8,"id":"1b6ca973","metadata":{"tags":["pdf-ignore"],"id":"1b6ca973","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654150935713,"user_tz":180,"elapsed":603591,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}},"outputId":"00d62d16-9150-42df-e8b9-2cdc2091a470"},"outputs":[{"output_type":"stream","name":"stdout","text":["cnn_vgg_19.ipynb\tcnn_vgg_19_old.ipynb  resnet_old_3.ipynb\n","cnn_vgg_19_old_2.ipynb\tcode\t\t      resnet_old_4.ipynb\n","cnn_vgg_19_old_3.ipynb\tresent_old_2.ipynb    resnet_old_5.ipynb\n","cnn_vgg_19_old_4.ipynb\tresnet.ipynb\t      resnet_old.ipynb\n","/content/drive/MyDrive/cs231n/project/code\n","/content/drive/My Drive/cs231n/project/code/images\n","(1, 500, 500, 3)\n","(2, 500, 500, 3)\n","(3, 500, 500, 3)\n","(4, 500, 500, 3)\n","(5, 500, 500, 3)\n","(6, 500, 500, 3)\n","(7, 500, 500, 3)\n","(8, 500, 500, 3)\n","(9, 500, 500, 3)\n","(10, 500, 500, 3)\n","(11, 500, 500, 3)\n","(12, 500, 500, 3)\n","(13, 500, 500, 3)\n","(14, 500, 500, 3)\n","(15, 500, 500, 3)\n","(16, 500, 500, 3)\n","(17, 500, 500, 3)\n","(18, 500, 500, 3)\n","(19, 500, 500, 3)\n","(20, 500, 500, 3)\n","(21, 500, 500, 3)\n","(22, 500, 500, 3)\n","(23, 500, 500, 3)\n","(24, 500, 500, 3)\n","(25, 500, 500, 3)\n","(26, 500, 500, 3)\n","(27, 500, 500, 3)\n","(28, 500, 500, 3)\n","(29, 500, 500, 3)\n","(30, 500, 500, 3)\n","(31, 500, 500, 3)\n","(32, 500, 500, 3)\n","(33, 500, 500, 3)\n","(34, 500, 500, 3)\n","(35, 500, 500, 3)\n","(36, 500, 500, 3)\n","(37, 500, 500, 3)\n","(38, 500, 500, 3)\n","(39, 500, 500, 3)\n","(40, 500, 500, 3)\n","(41, 500, 500, 3)\n","(42, 500, 500, 3)\n","(43, 500, 500, 3)\n","(44, 500, 500, 3)\n","(45, 500, 500, 3)\n","(46, 500, 500, 3)\n","(47, 500, 500, 3)\n","(48, 500, 500, 3)\n","(49, 500, 500, 3)\n","(50, 500, 500, 3)\n","(51, 500, 500, 3)\n","(52, 500, 500, 3)\n","(53, 500, 500, 3)\n","(54, 500, 500, 3)\n","(55, 500, 500, 3)\n","(56, 500, 500, 3)\n","(57, 500, 500, 3)\n","(58, 500, 500, 3)\n","(59, 500, 500, 3)\n","(60, 500, 500, 3)\n","(61, 500, 500, 3)\n","(62, 500, 500, 3)\n","(63, 500, 500, 3)\n","(64, 500, 500, 3)\n","(65, 500, 500, 3)\n","(66, 500, 500, 3)\n","(67, 500, 500, 3)\n","(68, 500, 500, 3)\n","(69, 500, 500, 3)\n","(70, 500, 500, 3)\n","(71, 500, 500, 3)\n","(72, 500, 500, 3)\n","(73, 500, 500, 3)\n","(74, 500, 500, 3)\n","(75, 500, 500, 3)\n","(76, 500, 500, 3)\n","(77, 500, 500, 3)\n","(78, 500, 500, 3)\n","(79, 500, 500, 3)\n","(80, 500, 500, 3)\n","(81, 500, 500, 3)\n","(82, 500, 500, 3)\n","(83, 500, 500, 3)\n","(84, 500, 500, 3)\n","(85, 500, 500, 3)\n","(86, 500, 500, 3)\n","(87, 500, 500, 3)\n","(88, 500, 500, 3)\n","(89, 500, 500, 3)\n","(90, 500, 500, 3)\n","(91, 500, 500, 3)\n","(92, 500, 500, 3)\n","(93, 500, 500, 3)\n","(94, 500, 500, 3)\n","(95, 500, 500, 3)\n","(96, 500, 500, 3)\n","(97, 500, 500, 3)\n","(98, 500, 500, 3)\n","(99, 500, 500, 3)\n","(100, 500, 500, 3)\n","(101, 500, 500, 3)\n","(102, 500, 500, 3)\n","(103, 500, 500, 3)\n","(104, 500, 500, 3)\n","(105, 500, 500, 3)\n","(106, 500, 500, 3)\n","(107, 500, 500, 3)\n","(108, 500, 500, 3)\n","(109, 500, 500, 3)\n","(110, 500, 500, 3)\n","(111, 500, 500, 3)\n","(112, 500, 500, 3)\n","(113, 500, 500, 3)\n","(114, 500, 500, 3)\n","(115, 500, 500, 3)\n","(116, 500, 500, 3)\n","(117, 500, 500, 3)\n","(118, 500, 500, 3)\n","(119, 500, 500, 3)\n","(120, 500, 500, 3)\n","(121, 500, 500, 3)\n","(122, 500, 500, 3)\n","(123, 500, 500, 3)\n","(124, 500, 500, 3)\n","(125, 500, 500, 3)\n","(126, 500, 500, 3)\n","(127, 500, 500, 3)\n","(128, 500, 500, 3)\n","(129, 500, 500, 3)\n","(130, 500, 500, 3)\n","(131, 500, 500, 3)\n","(132, 500, 500, 3)\n","(133, 500, 500, 3)\n","(134, 500, 500, 3)\n","(135, 500, 500, 3)\n","(136, 500, 500, 3)\n","(137, 500, 500, 3)\n","(138, 500, 500, 3)\n","(139, 500, 500, 3)\n","(140, 500, 500, 3)\n","(141, 500, 500, 3)\n","(142, 500, 500, 3)\n","(143, 500, 500, 3)\n","(144, 500, 500, 3)\n","(145, 500, 500, 3)\n","(146, 500, 500, 3)\n","(147, 500, 500, 3)\n","(148, 500, 500, 3)\n","(149, 500, 500, 3)\n","(150, 500, 500, 3)\n","(151, 500, 500, 3)\n","(152, 500, 500, 3)\n","(153, 500, 500, 3)\n","(154, 500, 500, 3)\n","(155, 500, 500, 3)\n","(156, 500, 500, 3)\n","(157, 500, 500, 3)\n","(158, 500, 500, 3)\n","(159, 500, 500, 3)\n","(160, 500, 500, 3)\n","(161, 500, 500, 3)\n","(162, 500, 500, 3)\n","(163, 500, 500, 3)\n","(164, 500, 500, 3)\n","(165, 500, 500, 3)\n","(166, 500, 500, 3)\n","(167, 500, 500, 3)\n","(168, 500, 500, 3)\n","(169, 500, 500, 3)\n","(170, 500, 500, 3)\n","(171, 500, 500, 3)\n","(172, 500, 500, 3)\n","(173, 500, 500, 3)\n","(174, 500, 500, 3)\n","(175, 500, 500, 3)\n","(176, 500, 500, 3)\n","(177, 500, 500, 3)\n","(178, 500, 500, 3)\n","(179, 500, 500, 3)\n","(180, 500, 500, 3)\n","(181, 500, 500, 3)\n","(182, 500, 500, 3)\n","(183, 500, 500, 3)\n","(184, 500, 500, 3)\n","(185, 500, 500, 3)\n","(186, 500, 500, 3)\n","(187, 500, 500, 3)\n","(188, 500, 500, 3)\n","(189, 500, 500, 3)\n","(190, 500, 500, 3)\n","(191, 500, 500, 3)\n","(192, 500, 500, 3)\n","(193, 500, 500, 3)\n","(194, 500, 500, 3)\n","(195, 500, 500, 3)\n","(196, 500, 500, 3)\n","(197, 500, 500, 3)\n","(198, 500, 500, 3)\n","(199, 500, 500, 3)\n","(200, 500, 500, 3)\n","(201, 500, 500, 3)\n","(202, 500, 500, 3)\n","(203, 500, 500, 3)\n","(204, 500, 500, 3)\n","(205, 500, 500, 3)\n","(206, 500, 500, 3)\n","(207, 500, 500, 3)\n","(208, 500, 500, 3)\n","(209, 500, 500, 3)\n","(210, 500, 500, 3)\n","(211, 500, 500, 3)\n","(212, 500, 500, 3)\n","(213, 500, 500, 3)\n","(214, 500, 500, 3)\n","(215, 500, 500, 3)\n","(216, 500, 500, 3)\n","(217, 500, 500, 3)\n","(218, 500, 500, 3)\n","(219, 500, 500, 3)\n","(220, 500, 500, 3)\n","(221, 500, 500, 3)\n","(222, 500, 500, 3)\n","(223, 500, 500, 3)\n","(224, 500, 500, 3)\n","(225, 500, 500, 3)\n","(226, 500, 500, 3)\n","(227, 500, 500, 3)\n","(228, 500, 500, 3)\n","(229, 500, 500, 3)\n","(230, 500, 500, 3)\n","(231, 500, 500, 3)\n","(232, 500, 500, 3)\n","(233, 500, 500, 3)\n","(234, 500, 500, 3)\n","(235, 500, 500, 3)\n","(236, 500, 500, 3)\n","(237, 500, 500, 3)\n","(238, 500, 500, 3)\n","(239, 500, 500, 3)\n","(240, 500, 500, 3)\n","(241, 500, 500, 3)\n","(242, 500, 500, 3)\n","(243, 500, 500, 3)\n","(244, 500, 500, 3)\n","(245, 500, 500, 3)\n","(246, 500, 500, 3)\n","(247, 500, 500, 3)\n","(248, 500, 500, 3)\n","(249, 500, 500, 3)\n","(250, 500, 500, 3)\n","(251, 500, 500, 3)\n","(252, 500, 500, 3)\n","(253, 500, 500, 3)\n","(254, 500, 500, 3)\n","(255, 500, 500, 3)\n","(256, 500, 500, 3)\n","(257, 500, 500, 3)\n","(258, 500, 500, 3)\n","(259, 500, 500, 3)\n","(260, 500, 500, 3)\n","(261, 500, 500, 3)\n","(262, 500, 500, 3)\n","(263, 500, 500, 3)\n","(264, 500, 500, 3)\n","(265, 500, 500, 3)\n","(266, 500, 500, 3)\n","(267, 500, 500, 3)\n","(268, 500, 500, 3)\n","(269, 500, 500, 3)\n","(270, 500, 500, 3)\n","(271, 500, 500, 3)\n","(272, 500, 500, 3)\n","(273, 500, 500, 3)\n","(274, 500, 500, 3)\n","(275, 500, 500, 3)\n","(276, 500, 500, 3)\n","(277, 500, 500, 3)\n","(278, 500, 500, 3)\n","(279, 500, 500, 3)\n","(280, 500, 500, 3)\n","(281, 500, 500, 3)\n","(282, 500, 500, 3)\n","(283, 500, 500, 3)\n","(284, 500, 500, 3)\n","(285, 500, 500, 3)\n","(286, 500, 500, 3)\n","(287, 500, 500, 3)\n","(288, 500, 500, 3)\n","(289, 500, 500, 3)\n","(290, 500, 500, 3)\n","(291, 500, 500, 3)\n","(292, 500, 500, 3)\n","(293, 500, 500, 3)\n","(294, 500, 500, 3)\n","(295, 500, 500, 3)\n","(296, 500, 500, 3)\n","(297, 500, 500, 3)\n","(298, 500, 500, 3)\n","(299, 500, 500, 3)\n","(300, 500, 500, 3)\n","(301, 500, 500, 3)\n","(302, 500, 500, 3)\n","(303, 500, 500, 3)\n","(304, 500, 500, 3)\n","(305, 500, 500, 3)\n","(306, 500, 500, 3)\n","(307, 500, 500, 3)\n","(308, 500, 500, 3)\n","(309, 500, 500, 3)\n","(310, 500, 500, 3)\n","(311, 500, 500, 3)\n","(312, 500, 500, 3)\n","(313, 500, 500, 3)\n","(314, 500, 500, 3)\n","(315, 500, 500, 3)\n","(316, 500, 500, 3)\n","(317, 500, 500, 3)\n","(318, 500, 500, 3)\n","(319, 500, 500, 3)\n","(320, 500, 500, 3)\n","(321, 500, 500, 3)\n","(322, 500, 500, 3)\n","(323, 500, 500, 3)\n","(324, 500, 500, 3)\n","(325, 500, 500, 3)\n","(326, 500, 500, 3)\n","(327, 500, 500, 3)\n","(328, 500, 500, 3)\n","(329, 500, 500, 3)\n","(330, 500, 500, 3)\n","(331, 500, 500, 3)\n","(332, 500, 500, 3)\n","(333, 500, 500, 3)\n","(334, 500, 500, 3)\n","(335, 500, 500, 3)\n","(336, 500, 500, 3)\n","(337, 500, 500, 3)\n","(338, 500, 500, 3)\n","(339, 500, 500, 3)\n","(340, 500, 500, 3)\n","(341, 500, 500, 3)\n","(342, 500, 500, 3)\n","(343, 500, 500, 3)\n","(344, 500, 500, 3)\n","(345, 500, 500, 3)\n","(346, 500, 500, 3)\n","(347, 500, 500, 3)\n","(348, 500, 500, 3)\n","(349, 500, 500, 3)\n","(350, 500, 500, 3)\n","(351, 500, 500, 3)\n","(352, 500, 500, 3)\n","(353, 500, 500, 3)\n","(354, 500, 500, 3)\n","(355, 500, 500, 3)\n","(356, 500, 500, 3)\n","(357, 500, 500, 3)\n","(358, 500, 500, 3)\n","(359, 500, 500, 3)\n","(360, 500, 500, 3)\n","(361, 500, 500, 3)\n","(362, 500, 500, 3)\n","(363, 500, 500, 3)\n","(364, 500, 500, 3)\n","(365, 500, 500, 3)\n","(366, 500, 500, 3)\n","(367, 500, 500, 3)\n","(368, 500, 500, 3)\n","(369, 500, 500, 3)\n","(370, 500, 500, 3)\n","(371, 500, 500, 3)\n","(372, 500, 500, 3)\n","(373, 500, 500, 3)\n","(374, 500, 500, 3)\n","(375, 500, 500, 3)\n","(376, 500, 500, 3)\n","(377, 500, 500, 3)\n","(378, 500, 500, 3)\n","(379, 500, 500, 3)\n","(380, 500, 500, 3)\n","(381, 500, 500, 3)\n","(382, 500, 500, 3)\n","(383, 500, 500, 3)\n","(384, 500, 500, 3)\n","(385, 500, 500, 3)\n","(386, 500, 500, 3)\n","(387, 500, 500, 3)\n","(388, 500, 500, 3)\n","(389, 500, 500, 3)\n","(390, 500, 500, 3)\n","(391, 500, 500, 3)\n","(392, 500, 500, 3)\n","(393, 500, 500, 3)\n","(394, 500, 500, 3)\n","(395, 500, 500, 3)\n","(396, 500, 500, 3)\n","(397, 500, 500, 3)\n","(398, 500, 500, 3)\n","(399, 500, 500, 3)\n","(400, 500, 500, 3)\n","(401, 500, 500, 3)\n","(402, 500, 500, 3)\n","(403, 500, 500, 3)\n","(404, 500, 500, 3)\n","(405, 500, 500, 3)\n","(406, 500, 500, 3)\n","(407, 500, 500, 3)\n","(408, 500, 500, 3)\n","(409, 500, 500, 3)\n","(410, 500, 500, 3)\n","(411, 500, 500, 3)\n","(412, 500, 500, 3)\n","(413, 500, 500, 3)\n","(414, 500, 500, 3)\n","(415, 500, 500, 3)\n","(416, 500, 500, 3)\n","(417, 500, 500, 3)\n","(418, 500, 500, 3)\n","(419, 500, 500, 3)\n","(420, 500, 500, 3)\n","(421, 500, 500, 3)\n","(422, 500, 500, 3)\n","(423, 500, 500, 3)\n","(424, 500, 500, 3)\n","(425, 500, 500, 3)\n","(426, 500, 500, 3)\n","(427, 500, 500, 3)\n","(428, 500, 500, 3)\n","(429, 500, 500, 3)\n","(430, 500, 500, 3)\n","(431, 500, 500, 3)\n","(432, 500, 500, 3)\n","(433, 500, 500, 3)\n","(434, 500, 500, 3)\n","(435, 500, 500, 3)\n","(436, 500, 500, 3)\n","(437, 500, 500, 3)\n","(438, 500, 500, 3)\n","(439, 500, 500, 3)\n","(440, 500, 500, 3)\n","(441, 500, 500, 3)\n","(442, 500, 500, 3)\n","(443, 500, 500, 3)\n","(444, 500, 500, 3)\n","(445, 500, 500, 3)\n","(446, 500, 500, 3)\n","(447, 500, 500, 3)\n","(448, 500, 500, 3)\n","(449, 500, 500, 3)\n","(450, 500, 500, 3)\n","(451, 500, 500, 3)\n","(452, 500, 500, 3)\n","(453, 500, 500, 3)\n","(454, 500, 500, 3)\n","(455, 500, 500, 3)\n","(456, 500, 500, 3)\n","(457, 500, 500, 3)\n","(458, 500, 500, 3)\n","(459, 500, 500, 3)\n","(460, 500, 500, 3)\n","(461, 500, 500, 3)\n","(462, 500, 500, 3)\n","(463, 500, 500, 3)\n","(464, 500, 500, 3)\n","(465, 500, 500, 3)\n","(466, 500, 500, 3)\n","(467, 500, 500, 3)\n","(468, 500, 500, 3)\n","(469, 500, 500, 3)\n","(470, 500, 500, 3)\n","(471, 500, 500, 3)\n","(472, 500, 500, 3)\n","(473, 500, 500, 3)\n","(474, 500, 500, 3)\n","(475, 500, 500, 3)\n","(476, 500, 500, 3)\n","(477, 500, 500, 3)\n","(478, 500, 500, 3)\n","(479, 500, 500, 3)\n","(480, 500, 500, 3)\n","(481, 500, 500, 3)\n","(482, 500, 500, 3)\n","(483, 500, 500, 3)\n","(484, 500, 500, 3)\n","(485, 500, 500, 3)\n","(486, 500, 500, 3)\n","(487, 500, 500, 3)\n","(488, 500, 500, 3)\n","(489, 500, 500, 3)\n","(490, 500, 500, 3)\n","(491, 500, 500, 3)\n","(492, 500, 500, 3)\n","(493, 500, 500, 3)\n","(494, 500, 500, 3)\n","(495, 500, 500, 3)\n","(496, 500, 500, 3)\n","(497, 500, 500, 3)\n","(498, 500, 500, 3)\n","(499, 500, 500, 3)\n","(500, 500, 500, 3)\n","(501, 500, 500, 3)\n","(502, 500, 500, 3)\n","(503, 500, 500, 3)\n","(504, 500, 500, 3)\n","(505, 500, 500, 3)\n","(506, 500, 500, 3)\n","(507, 500, 500, 3)\n","(508, 500, 500, 3)\n","(509, 500, 500, 3)\n","(510, 500, 500, 3)\n","(511, 500, 500, 3)\n","(512, 500, 500, 3)\n","(513, 500, 500, 3)\n","(514, 500, 500, 3)\n","(515, 500, 500, 3)\n","(516, 500, 500, 3)\n","(517, 500, 500, 3)\n","(518, 500, 500, 3)\n","(519, 500, 500, 3)\n","(520, 500, 500, 3)\n","(521, 500, 500, 3)\n","(522, 500, 500, 3)\n","(523, 500, 500, 3)\n","(524, 500, 500, 3)\n","(525, 500, 500, 3)\n","(526, 500, 500, 3)\n","(527, 500, 500, 3)\n","(528, 500, 500, 3)\n","(529, 500, 500, 3)\n","(530, 500, 500, 3)\n","(531, 500, 500, 3)\n","(532, 500, 500, 3)\n","(533, 500, 500, 3)\n","(534, 500, 500, 3)\n","(535, 500, 500, 3)\n","(536, 500, 500, 3)\n","(537, 500, 500, 3)\n","(538, 500, 500, 3)\n","(539, 500, 500, 3)\n","(540, 500, 500, 3)\n","(541, 500, 500, 3)\n","(542, 500, 500, 3)\n","(543, 500, 500, 3)\n","(544, 500, 500, 3)\n","(545, 500, 500, 3)\n","(546, 500, 500, 3)\n","(547, 500, 500, 3)\n","(548, 500, 500, 3)\n","(549, 500, 500, 3)\n","(550, 500, 500, 3)\n","(551, 500, 500, 3)\n","(552, 500, 500, 3)\n","(553, 500, 500, 3)\n","(554, 500, 500, 3)\n","(555, 500, 500, 3)\n","(556, 500, 500, 3)\n","(557, 500, 500, 3)\n","(558, 500, 500, 3)\n","(559, 500, 500, 3)\n","(560, 500, 500, 3)\n","(561, 500, 500, 3)\n","(562, 500, 500, 3)\n","(563, 500, 500, 3)\n","(564, 500, 500, 3)\n","(565, 500, 500, 3)\n","(566, 500, 500, 3)\n","(567, 500, 500, 3)\n","(568, 500, 500, 3)\n","(569, 500, 500, 3)\n","(570, 500, 500, 3)\n","(571, 500, 500, 3)\n","(572, 500, 500, 3)\n","(573, 500, 500, 3)\n","(574, 500, 500, 3)\n","(575, 500, 500, 3)\n","(576, 500, 500, 3)\n","(577, 500, 500, 3)\n","(578, 500, 500, 3)\n","(579, 500, 500, 3)\n","(580, 500, 500, 3)\n","(581, 500, 500, 3)\n","(582, 500, 500, 3)\n","(583, 500, 500, 3)\n","(584, 500, 500, 3)\n","(585, 500, 500, 3)\n","(586, 500, 500, 3)\n","(587, 500, 500, 3)\n","(588, 500, 500, 3)\n","(589, 500, 500, 3)\n","(590, 500, 500, 3)\n","(591, 500, 500, 3)\n","(592, 500, 500, 3)\n","(593, 500, 500, 3)\n","(594, 500, 500, 3)\n","(595, 500, 500, 3)\n","(596, 500, 500, 3)\n","(597, 500, 500, 3)\n","(598, 500, 500, 3)\n","(599, 500, 500, 3)\n","(600, 500, 500, 3)\n","(601, 500, 500, 3)\n","(602, 500, 500, 3)\n","(603, 500, 500, 3)\n","(604, 500, 500, 3)\n","(605, 500, 500, 3)\n","(606, 500, 500, 3)\n","(607, 500, 500, 3)\n","(608, 500, 500, 3)\n","(609, 500, 500, 3)\n","(610, 500, 500, 3)\n","(611, 500, 500, 3)\n","(612, 500, 500, 3)\n","(613, 500, 500, 3)\n","(614, 500, 500, 3)\n","(615, 500, 500, 3)\n","(616, 500, 500, 3)\n","(617, 500, 500, 3)\n","(618, 500, 500, 3)\n","(619, 500, 500, 3)\n","(620, 500, 500, 3)\n","(621, 500, 500, 3)\n","(622, 500, 500, 3)\n","(623, 500, 500, 3)\n","(624, 500, 500, 3)\n","(625, 500, 500, 3)\n","(626, 500, 500, 3)\n","(627, 500, 500, 3)\n","(628, 500, 500, 3)\n","(629, 500, 500, 3)\n","(630, 500, 500, 3)\n","(631, 500, 500, 3)\n","(632, 500, 500, 3)\n","(633, 500, 500, 3)\n","(634, 500, 500, 3)\n","(635, 500, 500, 3)\n","(636, 500, 500, 3)\n","(637, 500, 500, 3)\n","(638, 500, 500, 3)\n","(639, 500, 500, 3)\n","(640, 500, 500, 3)\n","(641, 500, 500, 3)\n","(642, 500, 500, 3)\n","(643, 500, 500, 3)\n","(644, 500, 500, 3)\n","(645, 500, 500, 3)\n","(646, 500, 500, 3)\n","(647, 500, 500, 3)\n","(648, 500, 500, 3)\n","(649, 500, 500, 3)\n","(650, 500, 500, 3)\n","(651, 500, 500, 3)\n","(652, 500, 500, 3)\n","(653, 500, 500, 3)\n","(654, 500, 500, 3)\n","(655, 500, 500, 3)\n","(656, 500, 500, 3)\n","(657, 500, 500, 3)\n","(658, 500, 500, 3)\n","(659, 500, 500, 3)\n","(660, 500, 500, 3)\n","(661, 500, 500, 3)\n","(662, 500, 500, 3)\n","(663, 500, 500, 3)\n","(664, 500, 500, 3)\n","(665, 500, 500, 3)\n","(666, 500, 500, 3)\n","(667, 500, 500, 3)\n","(668, 500, 500, 3)\n","(669, 500, 500, 3)\n","(670, 500, 500, 3)\n","(671, 500, 500, 3)\n","(672, 500, 500, 3)\n","(673, 500, 500, 3)\n","(674, 500, 500, 3)\n","(675, 500, 500, 3)\n","(676, 500, 500, 3)\n","(677, 500, 500, 3)\n","(678, 500, 500, 3)\n","(679, 500, 500, 3)\n","(680, 500, 500, 3)\n","(681, 500, 500, 3)\n","(682, 500, 500, 3)\n","(683, 500, 500, 3)\n","(684, 500, 500, 3)\n","(685, 500, 500, 3)\n","(686, 500, 500, 3)\n","(687, 500, 500, 3)\n","(688, 500, 500, 3)\n","(689, 500, 500, 3)\n","(690, 500, 500, 3)\n","(691, 500, 500, 3)\n","(692, 500, 500, 3)\n","(693, 500, 500, 3)\n","(694, 500, 500, 3)\n","(695, 500, 500, 3)\n","(696, 500, 500, 3)\n","(697, 500, 500, 3)\n","(698, 500, 500, 3)\n","(699, 500, 500, 3)\n","(700, 500, 500, 3)\n","(701, 500, 500, 3)\n","(702, 500, 500, 3)\n","(703, 500, 500, 3)\n","(704, 500, 500, 3)\n","(705, 500, 500, 3)\n","(706, 500, 500, 3)\n","(707, 500, 500, 3)\n","(708, 500, 500, 3)\n","(709, 500, 500, 3)\n","(710, 500, 500, 3)\n","(711, 500, 500, 3)\n","(712, 500, 500, 3)\n","(713, 500, 500, 3)\n","(714, 500, 500, 3)\n","(715, 500, 500, 3)\n","(716, 500, 500, 3)\n","(717, 500, 500, 3)\n","(718, 500, 500, 3)\n","(719, 500, 500, 3)\n","(720, 500, 500, 3)\n","(721, 500, 500, 3)\n","(722, 500, 500, 3)\n","(723, 500, 500, 3)\n","(724, 500, 500, 3)\n","(725, 500, 500, 3)\n","(726, 500, 500, 3)\n","(727, 500, 500, 3)\n","(728, 500, 500, 3)\n","(729, 500, 500, 3)\n","(730, 500, 500, 3)\n","(731, 500, 500, 3)\n","(732, 500, 500, 3)\n","(733, 500, 500, 3)\n","(734, 500, 500, 3)\n","(735, 500, 500, 3)\n","(736, 500, 500, 3)\n","(737, 500, 500, 3)\n","(738, 500, 500, 3)\n","(739, 500, 500, 3)\n","(740, 500, 500, 3)\n","(741, 500, 500, 3)\n","(742, 500, 500, 3)\n","(743, 500, 500, 3)\n","(744, 500, 500, 3)\n","(745, 500, 500, 3)\n","(746, 500, 500, 3)\n","(747, 500, 500, 3)\n","(748, 500, 500, 3)\n","(749, 500, 500, 3)\n","(750, 500, 500, 3)\n","(751, 500, 500, 3)\n","(752, 500, 500, 3)\n","(753, 500, 500, 3)\n","(754, 500, 500, 3)\n","(755, 500, 500, 3)\n","(756, 500, 500, 3)\n","(757, 500, 500, 3)\n","(758, 500, 500, 3)\n","(759, 500, 500, 3)\n","(760, 500, 500, 3)\n","(761, 500, 500, 3)\n","(762, 500, 500, 3)\n","(763, 500, 500, 3)\n","(764, 500, 500, 3)\n","(765, 500, 500, 3)\n","(766, 500, 500, 3)\n","(767, 500, 500, 3)\n","(768, 500, 500, 3)\n","(769, 500, 500, 3)\n","(770, 500, 500, 3)\n","(771, 500, 500, 3)\n","(772, 500, 500, 3)\n","(773, 500, 500, 3)\n","(774, 500, 500, 3)\n","(775, 500, 500, 3)\n","(776, 500, 500, 3)\n","(777, 500, 500, 3)\n","(778, 500, 500, 3)\n","(779, 500, 500, 3)\n","(780, 500, 500, 3)\n","(781, 500, 500, 3)\n","(782, 500, 500, 3)\n","(783, 500, 500, 3)\n","(784, 500, 500, 3)\n","(785, 500, 500, 3)\n","(786, 500, 500, 3)\n","(787, 500, 500, 3)\n","(788, 500, 500, 3)\n","(789, 500, 500, 3)\n","(790, 500, 500, 3)\n","(791, 500, 500, 3)\n","(792, 500, 500, 3)\n","(793, 500, 500, 3)\n","(794, 500, 500, 3)\n","(795, 500, 500, 3)\n","(796, 500, 500, 3)\n","(797, 500, 500, 3)\n","(798, 500, 500, 3)\n","(799, 500, 500, 3)\n","(800, 500, 500, 3)\n","(801, 500, 500, 3)\n","(802, 500, 500, 3)\n","(803, 500, 500, 3)\n","(804, 500, 500, 3)\n","(805, 500, 500, 3)\n","(806, 500, 500, 3)\n","(807, 500, 500, 3)\n","(808, 500, 500, 3)\n","(809, 500, 500, 3)\n","(810, 500, 500, 3)\n","(811, 500, 500, 3)\n","(812, 500, 500, 3)\n","(813, 500, 500, 3)\n","(814, 500, 500, 3)\n","(815, 500, 500, 3)\n","(816, 500, 500, 3)\n","(817, 500, 500, 3)\n","(818, 500, 500, 3)\n","(819, 500, 500, 3)\n","(820, 500, 500, 3)\n","(821, 500, 500, 3)\n","(822, 500, 500, 3)\n","(823, 500, 500, 3)\n","(824, 500, 500, 3)\n","(825, 500, 500, 3)\n","(826, 500, 500, 3)\n","(827, 500, 500, 3)\n","(828, 500, 500, 3)\n","(829, 500, 500, 3)\n","(830, 500, 500, 3)\n","(831, 500, 500, 3)\n","(832, 500, 500, 3)\n","(833, 500, 500, 3)\n","(834, 500, 500, 3)\n","(835, 500, 500, 3)\n","(836, 500, 500, 3)\n","(837, 500, 500, 3)\n","(838, 500, 500, 3)\n","(839, 500, 500, 3)\n","(840, 500, 500, 3)\n","(841, 500, 500, 3)\n","(842, 500, 500, 3)\n","(843, 500, 500, 3)\n","(844, 500, 500, 3)\n","(845, 500, 500, 3)\n","(846, 500, 500, 3)\n","(847, 500, 500, 3)\n","(848, 500, 500, 3)\n","(849, 500, 500, 3)\n","(850, 500, 500, 3)\n","(851, 500, 500, 3)\n","(852, 500, 500, 3)\n","(853, 500, 500, 3)\n","(854, 500, 500, 3)\n","(855, 500, 500, 3)\n","(856, 500, 500, 3)\n","(857, 500, 500, 3)\n","(858, 500, 500, 3)\n","(859, 500, 500, 3)\n","(860, 500, 500, 3)\n","(861, 500, 500, 3)\n","(862, 500, 500, 3)\n","(863, 500, 500, 3)\n","(864, 500, 500, 3)\n","(865, 500, 500, 3)\n","(866, 500, 500, 3)\n","(867, 500, 500, 3)\n","(868, 500, 500, 3)\n","(869, 500, 500, 3)\n","(870, 500, 500, 3)\n","(871, 500, 500, 3)\n","(872, 500, 500, 3)\n","(873, 500, 500, 3)\n","(874, 500, 500, 3)\n","(875, 500, 500, 3)\n","(876, 500, 500, 3)\n","(877, 500, 500, 3)\n","(878, 500, 500, 3)\n","(879, 500, 500, 3)\n","(880, 500, 500, 3)\n","(881, 500, 500, 3)\n","(882, 500, 500, 3)\n","(883, 500, 500, 3)\n","(884, 500, 500, 3)\n","(885, 500, 500, 3)\n","(886, 500, 500, 3)\n","(887, 500, 500, 3)\n","(888, 500, 500, 3)\n","(889, 500, 500, 3)\n","(890, 500, 500, 3)\n","(891, 500, 500, 3)\n","(892, 500, 500, 3)\n","(893, 500, 500, 3)\n","(894, 500, 500, 3)\n","(895, 500, 500, 3)\n","(896, 500, 500, 3)\n","(897, 500, 500, 3)\n","(898, 500, 500, 3)\n","(899, 500, 500, 3)\n","(900, 500, 500, 3)\n","(901, 500, 500, 3)\n","(902, 500, 500, 3)\n","(903, 500, 500, 3)\n","(904, 500, 500, 3)\n","(905, 500, 500, 3)\n","(906, 500, 500, 3)\n","(907, 500, 500, 3)\n","(908, 500, 500, 3)\n","(909, 500, 500, 3)\n","(910, 500, 500, 3)\n","/content/drive/My Drive/cs231n/project\n"]}],"source":["# Loading the data \n","!ls\n","%cd code\n","orig_x, orig_y = utils.read_data()\n","orig_y = utils.classification(orig_y, orig_y)\n","orig_y = utils.one_hot_labels(orig_y)\n","orig_x = orig_x / 255.\n","#orig_x -= 0.5\n","#orig_x *= 2\n","# orig_x = orig_x-np.mean(orig_x)\n","# Create the training sample\n","train_x, val_test_x, train_y, val_test_y = train_test_split(orig_x, orig_y, test_size=0.3, random_state=1)\n","# Split the remaining observations into validation and test\n","val_x, test_x, val_y, test_y = train_test_split(val_test_x, val_test_y, test_size=0.33, random_state=1)\n","%cd .."]},{"cell_type":"markdown","source":["# Check the dataset"],"metadata":{"id":"amEHUeZLsrku"},"id":"amEHUeZLsrku"},{"cell_type":"code","source":["# Example of an image from the dataset\n","#index = 270\n","#plt.imshow(orig_x[index])\n","#print(orig_x[index])\n","\n","print(\"number of training examples = \" + str(train_x.shape[0]))\n","print(\"number of validation examples = \" + str(val_x.shape[0]))\n","print(\"X_train shape: \" + str(train_x.shape))\n","print(\"Y_train shape: \" + str(train_y.shape))\n","print(\"X_val shape: \" + str(val_x.shape))\n","print(\"Y_val shape: \" + str(val_y.shape))\n","print(\"X_test shape: \" + str(test_x.shape))\n","print(\"Y_test shape: \" + str(test_y.shape))"],"metadata":{"id":"_OAvyppxjx_H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654150939964,"user_tz":180,"elapsed":349,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}},"outputId":"b569313c-bb0f-455f-ec39-adb8bc182cff"},"id":"_OAvyppxjx_H","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["number of training examples = 637\n","number of validation examples = 182\n","X_train shape: (637, 500, 500, 3)\n","Y_train shape: (637, 7)\n","X_val shape: (182, 500, 500, 3)\n","Y_val shape: (182, 7)\n","X_test shape: (91, 500, 500, 3)\n","Y_test shape: (91, 7)\n"]}]},{"cell_type":"markdown","id":"a527a66e","metadata":{"id":"a527a66e"},"source":["# Create the model - using tensorflow"]},{"cell_type":"code","execution_count":10,"id":"26b58b5a","metadata":{"id":"26b58b5a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654150968930,"user_tz":180,"elapsed":20415,"user":{"displayName":"Bohdan junior","userId":"09109244157026443917"}},"outputId":"a8286ab0-50fd-4cee-9878-61248649054c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons==0.16.1\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 13.8 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.16.1) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.16.1\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 112, 112, 64  9472        ['zero_padding2d[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 112, 112, 64  256        ['conv2d[0][0]']                 \n"," alization)                     )                                                                 \n","                                                                                                  \n"," activation (Activation)        (None, 112, 112, 64  0           ['batch_normalization[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 55, 55, 64)   0           ['activation[0][0]']             \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 55, 55, 64)   4160        ['max_pooling2d[0][0]']          \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_1 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 55, 55, 64)   36928       ['activation_1[0][0]']           \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_2 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 55, 55, 256)  16640       ['activation_2[0][0]']           \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 55, 55, 256)  16640       ['max_pooling2d[0][0]']          \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 55, 55, 256)  1024       ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 55, 55, 256)  1024       ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add (Add)                      (None, 55, 55, 256)  0           ['batch_normalization_3[0][0]',  \n","                                                                  'batch_normalization_4[0][0]']  \n","                                                                                                  \n"," activation_3 (Activation)      (None, 55, 55, 256)  0           ['add[0][0]']                    \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 55, 55, 64)   16448       ['activation_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 55, 55, 64)   36928       ['activation_4[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_5 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 55, 55, 256)  16640       ['activation_5[0][0]']           \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 55, 55, 256)  1024       ['conv2d_7[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_1 (Add)                    (None, 55, 55, 256)  0           ['batch_normalization_7[0][0]',  \n","                                                                  'activation_3[0][0]']           \n","                                                                                                  \n"," activation_6 (Activation)      (None, 55, 55, 256)  0           ['add_1[0][0]']                  \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 55, 55, 64)   16448       ['activation_6[0][0]']           \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_8[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_7 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 55, 55, 64)   36928       ['activation_7[0][0]']           \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_9[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_8 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 55, 55, 256)  16640       ['activation_8[0][0]']           \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 55, 55, 256)  1024       ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_2 (Add)                    (None, 55, 55, 256)  0           ['batch_normalization_10[0][0]', \n","                                                                  'activation_6[0][0]']           \n","                                                                                                  \n"," activation_9 (Activation)      (None, 55, 55, 256)  0           ['add_2[0][0]']                  \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 28, 28, 128)  32896       ['activation_9[0][0]']           \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 28, 28, 128)  512        ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_10 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_10[0][0]']          \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 28, 28, 128)  512        ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_11 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_11[0][0]']          \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 28, 28, 512)  131584      ['activation_9[0][0]']           \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_3 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_13[0][0]', \n","                                                                  'batch_normalization_14[0][0]'] \n","                                                                                                  \n"," activation_12 (Activation)     (None, 28, 28, 512)  0           ['add_3[0][0]']                  \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_12[0][0]']          \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 28, 28, 128)  512        ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_13[0][0]']          \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 28, 28, 128)  512        ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_14 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_14[0][0]']          \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_4 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_17[0][0]', \n","                                                                  'activation_12[0][0]']          \n","                                                                                                  \n"," activation_15 (Activation)     (None, 28, 28, 512)  0           ['add_4[0][0]']                  \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 28, 28, 128)  512        ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_16[0][0]']          \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 28, 28, 128)  512        ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_17 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_17[0][0]']          \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_5 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_20[0][0]', \n","                                                                  'activation_15[0][0]']          \n","                                                                                                  \n"," activation_18 (Activation)     (None, 28, 28, 512)  0           ['add_5[0][0]']                  \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_18[0][0]']          \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 28, 28, 128)  512        ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_21[0][0]'] \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_19[0][0]']          \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 28, 28, 128)  512        ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_20[0][0]']          \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_6 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_23[0][0]', \n","                                                                  'activation_18[0][0]']          \n","                                                                                                  \n"," activation_21 (Activation)     (None, 28, 28, 512)  0           ['add_6[0][0]']                  \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_21[0][0]']          \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 28, 28, 128)  512        ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_24[0][0]'] \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_22[0][0]']          \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 28, 28, 128)  512        ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_23 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_23[0][0]']          \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_26[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_7 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_26[0][0]', \n","                                                                  'activation_21[0][0]']          \n","                                                                                                  \n"," activation_24 (Activation)     (None, 28, 28, 512)  0           ['add_7[0][0]']                  \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_24[0][0]']          \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 28, 28, 128)  512        ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_25 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_27[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_25[0][0]']          \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 28, 28, 128)  512        ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_26[0][0]']          \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_29[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_8 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_29[0][0]', \n","                                                                  'activation_24[0][0]']          \n","                                                                                                  \n"," activation_27 (Activation)     (None, 28, 28, 512)  0           ['add_8[0][0]']                  \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 28, 28, 128)  512        ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_30[0][0]'] \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_28[0][0]']          \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 28, 28, 128)  512        ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_29 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_29[0][0]']          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_9 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_32[0][0]', \n","                                                                  'activation_27[0][0]']          \n","                                                                                                  \n"," activation_30 (Activation)     (None, 28, 28, 512)  0           ['add_9[0][0]']                  \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_30[0][0]']          \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 28, 28, 128)  512        ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_33[0][0]'] \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_31[0][0]']          \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 28, 28, 128)  512        ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_32 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_32[0][0]']          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_10 (Add)                   (None, 28, 28, 512)  0           ['batch_normalization_35[0][0]', \n","                                                                  'activation_30[0][0]']          \n","                                                                                                  \n"," activation_33 (Activation)     (None, 28, 28, 512)  0           ['add_10[0][0]']                 \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 14, 14, 256)  131328      ['activation_33[0][0]']          \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_34 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_36[0][0]'] \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_34[0][0]']          \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_35 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_37[0][0]'] \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_35[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 14, 14, 1024  525312      ['activation_33[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_38[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_39[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_11 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_38[0][0]', \n","                                )                                 'batch_normalization_39[0][0]'] \n","                                                                                                  \n"," activation_36 (Activation)     (None, 14, 14, 1024  0           ['add_11[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_36[0][0]']          \n","                                                                                                  \n"," batch_normalization_40 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_37 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_40[0][0]'] \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_37[0][0]']          \n","                                                                                                  \n"," batch_normalization_41 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_38 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_38[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_42 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_42[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_12 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_42[0][0]', \n","                                )                                 'activation_36[0][0]']          \n","                                                                                                  \n"," activation_39 (Activation)     (None, 14, 14, 1024  0           ['add_12[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_39[0][0]']          \n","                                                                                                  \n"," batch_normalization_43 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_40 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_43[0][0]'] \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_40[0][0]']          \n","                                                                                                  \n"," batch_normalization_44 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_44[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_41 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_44[0][0]'] \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_41[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_45 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_45[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_13 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_45[0][0]', \n","                                )                                 'activation_39[0][0]']          \n","                                                                                                  \n"," activation_42 (Activation)     (None, 14, 14, 1024  0           ['add_13[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_42[0][0]']          \n","                                                                                                  \n"," batch_normalization_46 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_46[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_43 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_46[0][0]'] \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_43[0][0]']          \n","                                                                                                  \n"," batch_normalization_47 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_44 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_47[0][0]'] \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_44[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_48 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_48[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_14 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_48[0][0]', \n","                                )                                 'activation_42[0][0]']          \n","                                                                                                  \n"," activation_45 (Activation)     (None, 14, 14, 1024  0           ['add_14[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_45[0][0]']          \n","                                                                                                  \n"," batch_normalization_49 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_49[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_46 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_49[0][0]'] \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_46[0][0]']          \n","                                                                                                  \n"," batch_normalization_50 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_50[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_47 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_47[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_51 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_51[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_15 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_51[0][0]', \n","                                )                                 'activation_45[0][0]']          \n","                                                                                                  \n"," activation_48 (Activation)     (None, 14, 14, 1024  0           ['add_15[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_48[0][0]']          \n","                                                                                                  \n"," batch_normalization_52 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_52[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_49 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_52[0][0]'] \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_49[0][0]']          \n","                                                                                                  \n"," batch_normalization_53 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_53[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_50 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_53[0][0]'] \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_50[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_54[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_16 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_54[0][0]', \n","                                )                                 'activation_48[0][0]']          \n","                                                                                                  \n"," activation_51 (Activation)     (None, 14, 14, 1024  0           ['add_16[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_51[0][0]']          \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_55[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_52 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_52[0][0]']          \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_56[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_53 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_53[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_57[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_17 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_57[0][0]', \n","                                )                                 'activation_51[0][0]']          \n","                                                                                                  \n"," activation_54 (Activation)     (None, 14, 14, 1024  0           ['add_17[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_54[0][0]']          \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_58[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_55 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_58[0][0]'] \n","                                                                                                  \n"," conv2d_59 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_55[0][0]']          \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_59[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_56 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_59[0][0]'] \n","                                                                                                  \n"," conv2d_60 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_56[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_60[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_18 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_60[0][0]', \n","                                )                                 'activation_54[0][0]']          \n","                                                                                                  \n"," activation_57 (Activation)     (None, 14, 14, 1024  0           ['add_18[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_61 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_57[0][0]']          \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_61[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_58 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," conv2d_62 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_58[0][0]']          \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_62[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_59 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," conv2d_63 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_59[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_63[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_19 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_63[0][0]', \n","                                )                                 'activation_57[0][0]']          \n","                                                                                                  \n"," activation_60 (Activation)     (None, 14, 14, 1024  0           ['add_19[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_64 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_60[0][0]']          \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_64[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_61 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_64[0][0]'] \n","                                                                                                  \n"," conv2d_65 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_61[0][0]']          \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_65[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_62 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_65[0][0]'] \n","                                                                                                  \n"," conv2d_66 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_62[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_66[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_20 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_66[0][0]', \n","                                )                                 'activation_60[0][0]']          \n","                                                                                                  \n"," activation_63 (Activation)     (None, 14, 14, 1024  0           ['add_20[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_67 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_63[0][0]']          \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_67[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_64 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_67[0][0]'] \n","                                                                                                  \n"," conv2d_68 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_64[0][0]']          \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_68[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_65 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_68[0][0]'] \n","                                                                                                  \n"," conv2d_69 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_65[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_69[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_21 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_69[0][0]', \n","                                )                                 'activation_63[0][0]']          \n","                                                                                                  \n"," activation_66 (Activation)     (None, 14, 14, 1024  0           ['add_21[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_70 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_66[0][0]']          \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_70[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_67 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_70[0][0]'] \n","                                                                                                  \n"," conv2d_71 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_67[0][0]']          \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_71[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_68 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_71[0][0]'] \n","                                                                                                  \n"," conv2d_72 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_68[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_72 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_72[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_22 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_72[0][0]', \n","                                )                                 'activation_66[0][0]']          \n","                                                                                                  \n"," activation_69 (Activation)     (None, 14, 14, 1024  0           ['add_22[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_73 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_69[0][0]']          \n","                                                                                                  \n"," batch_normalization_73 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_73[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_70 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_73[0][0]'] \n","                                                                                                  \n"," conv2d_74 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_70[0][0]']          \n","                                                                                                  \n"," batch_normalization_74 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_74[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_71 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_74[0][0]'] \n","                                                                                                  \n"," conv2d_75 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_71[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_75 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_75[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_23 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_75[0][0]', \n","                                )                                 'activation_69[0][0]']          \n","                                                                                                  \n"," activation_72 (Activation)     (None, 14, 14, 1024  0           ['add_23[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_76 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_72[0][0]']          \n","                                                                                                  \n"," batch_normalization_76 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_76[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_73 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_76[0][0]'] \n","                                                                                                  \n"," conv2d_77 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_73[0][0]']          \n","                                                                                                  \n"," batch_normalization_77 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_77[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_74 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_77[0][0]'] \n","                                                                                                  \n"," conv2d_78 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_74[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_78 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_78[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_24 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_78[0][0]', \n","                                )                                 'activation_72[0][0]']          \n","                                                                                                  \n"," activation_75 (Activation)     (None, 14, 14, 1024  0           ['add_24[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_79 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_75[0][0]']          \n","                                                                                                  \n"," batch_normalization_79 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_79[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_76 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_79[0][0]'] \n","                                                                                                  \n"," conv2d_80 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_76[0][0]']          \n","                                                                                                  \n"," batch_normalization_80 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_80[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_77 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_80[0][0]'] \n","                                                                                                  \n"," conv2d_81 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_77[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_81 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_81[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_25 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_81[0][0]', \n","                                )                                 'activation_75[0][0]']          \n","                                                                                                  \n"," activation_78 (Activation)     (None, 14, 14, 1024  0           ['add_25[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_82 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_78[0][0]']          \n","                                                                                                  \n"," batch_normalization_82 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_82[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_79 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_82[0][0]'] \n","                                                                                                  \n"," conv2d_83 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_79[0][0]']          \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_83[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_80 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_83[0][0]'] \n","                                                                                                  \n"," conv2d_84 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_80[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_84 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_84[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_26 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_84[0][0]', \n","                                )                                 'activation_78[0][0]']          \n","                                                                                                  \n"," activation_81 (Activation)     (None, 14, 14, 1024  0           ['add_26[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_85 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_81[0][0]']          \n","                                                                                                  \n"," batch_normalization_85 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_85[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_82 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_85[0][0]'] \n","                                                                                                  \n"," conv2d_86 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_82[0][0]']          \n","                                                                                                  \n"," batch_normalization_86 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_86[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_83 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_86[0][0]'] \n","                                                                                                  \n"," conv2d_87 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_83[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_87 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_87[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_27 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_87[0][0]', \n","                                )                                 'activation_81[0][0]']          \n","                                                                                                  \n"," activation_84 (Activation)     (None, 14, 14, 1024  0           ['add_27[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_88 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_84[0][0]']          \n","                                                                                                  \n"," batch_normalization_88 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_88[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_85 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_88[0][0]'] \n","                                                                                                  \n"," conv2d_89 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_85[0][0]']          \n","                                                                                                  \n"," batch_normalization_89 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_89[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_86 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_89[0][0]'] \n","                                                                                                  \n"," conv2d_90 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_86[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_90 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_90[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_28 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_90[0][0]', \n","                                )                                 'activation_84[0][0]']          \n","                                                                                                  \n"," activation_87 (Activation)     (None, 14, 14, 1024  0           ['add_28[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_91 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_87[0][0]']          \n","                                                                                                  \n"," batch_normalization_91 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_91[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_88 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_91[0][0]'] \n","                                                                                                  \n"," conv2d_92 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_88[0][0]']          \n","                                                                                                  \n"," batch_normalization_92 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_92[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_89 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_92[0][0]'] \n","                                                                                                  \n"," conv2d_93 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_89[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_93 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_93[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_29 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_93[0][0]', \n","                                )                                 'activation_87[0][0]']          \n","                                                                                                  \n"," activation_90 (Activation)     (None, 14, 14, 1024  0           ['add_29[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_94 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_90[0][0]']          \n","                                                                                                  \n"," batch_normalization_94 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_94[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_91 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_94[0][0]'] \n","                                                                                                  \n"," conv2d_95 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_91[0][0]']          \n","                                                                                                  \n"," batch_normalization_95 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_95[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_92 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_95[0][0]'] \n","                                                                                                  \n"," conv2d_96 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_92[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_96 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_96[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_30 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_96[0][0]', \n","                                )                                 'activation_90[0][0]']          \n","                                                                                                  \n"," activation_93 (Activation)     (None, 14, 14, 1024  0           ['add_30[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_97 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_93[0][0]']          \n","                                                                                                  \n"," batch_normalization_97 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_97[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_94 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_97[0][0]'] \n","                                                                                                  \n"," conv2d_98 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_94[0][0]']          \n","                                                                                                  \n"," batch_normalization_98 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_98[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_95 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_98[0][0]'] \n","                                                                                                  \n"," conv2d_99 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_95[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_99 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_99[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," add_31 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_99[0][0]', \n","                                )                                 'activation_93[0][0]']          \n","                                                                                                  \n"," activation_96 (Activation)     (None, 14, 14, 1024  0           ['add_31[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_100 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_96[0][0]']          \n","                                                                                                  \n"," batch_normalization_100 (Batch  (None, 14, 14, 256)  1024       ['conv2d_100[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_97 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_100[0][0]']\n","                                                                                                  \n"," conv2d_101 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_97[0][0]']          \n","                                                                                                  \n"," batch_normalization_101 (Batch  (None, 14, 14, 256)  1024       ['conv2d_101[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_98 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_101[0][0]']\n","                                                                                                  \n"," conv2d_102 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_98[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_102 (Batch  (None, 14, 14, 1024  4096       ['conv2d_102[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_32 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_102[0][0]',\n","                                )                                 'activation_96[0][0]']          \n","                                                                                                  \n"," activation_99 (Activation)     (None, 14, 14, 1024  0           ['add_32[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_103 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_99[0][0]']          \n","                                                                                                  \n"," batch_normalization_103 (Batch  (None, 14, 14, 256)  1024       ['conv2d_103[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_100 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_103[0][0]']\n","                                                                                                  \n"," conv2d_104 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_100[0][0]']         \n","                                                                                                  \n"," batch_normalization_104 (Batch  (None, 14, 14, 256)  1024       ['conv2d_104[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_101 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_104[0][0]']\n","                                                                                                  \n"," conv2d_105 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_101[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_105 (Batch  (None, 14, 14, 1024  4096       ['conv2d_105[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_33 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_105[0][0]',\n","                                )                                 'activation_99[0][0]']          \n","                                                                                                  \n"," activation_102 (Activation)    (None, 14, 14, 1024  0           ['add_33[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_106 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_102[0][0]']         \n","                                                                                                  \n"," batch_normalization_106 (Batch  (None, 14, 14, 256)  1024       ['conv2d_106[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_103 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_106[0][0]']\n","                                                                                                  \n"," conv2d_107 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_103[0][0]']         \n","                                                                                                  \n"," batch_normalization_107 (Batch  (None, 14, 14, 256)  1024       ['conv2d_107[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_104 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_107[0][0]']\n","                                                                                                  \n"," conv2d_108 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_104[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_108 (Batch  (None, 14, 14, 1024  4096       ['conv2d_108[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_34 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_108[0][0]',\n","                                )                                 'activation_102[0][0]']         \n","                                                                                                  \n"," activation_105 (Activation)    (None, 14, 14, 1024  0           ['add_34[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_109 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_105[0][0]']         \n","                                                                                                  \n"," batch_normalization_109 (Batch  (None, 14, 14, 256)  1024       ['conv2d_109[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_106 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_109[0][0]']\n","                                                                                                  \n"," conv2d_110 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_106[0][0]']         \n","                                                                                                  \n"," batch_normalization_110 (Batch  (None, 14, 14, 256)  1024       ['conv2d_110[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_107 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_110[0][0]']\n","                                                                                                  \n"," conv2d_111 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_107[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_111 (Batch  (None, 14, 14, 1024  4096       ['conv2d_111[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_35 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_111[0][0]',\n","                                )                                 'activation_105[0][0]']         \n","                                                                                                  \n"," activation_108 (Activation)    (None, 14, 14, 1024  0           ['add_35[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_112 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_108[0][0]']         \n","                                                                                                  \n"," batch_normalization_112 (Batch  (None, 14, 14, 256)  1024       ['conv2d_112[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_109 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_112[0][0]']\n","                                                                                                  \n"," conv2d_113 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_109[0][0]']         \n","                                                                                                  \n"," batch_normalization_113 (Batch  (None, 14, 14, 256)  1024       ['conv2d_113[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_110 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_113[0][0]']\n","                                                                                                  \n"," conv2d_114 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_110[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_114 (Batch  (None, 14, 14, 1024  4096       ['conv2d_114[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_36 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_114[0][0]',\n","                                )                                 'activation_108[0][0]']         \n","                                                                                                  \n"," activation_111 (Activation)    (None, 14, 14, 1024  0           ['add_36[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_115 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_111[0][0]']         \n","                                                                                                  \n"," batch_normalization_115 (Batch  (None, 14, 14, 256)  1024       ['conv2d_115[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_112 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_115[0][0]']\n","                                                                                                  \n"," conv2d_116 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_112[0][0]']         \n","                                                                                                  \n"," batch_normalization_116 (Batch  (None, 14, 14, 256)  1024       ['conv2d_116[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_113 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_116[0][0]']\n","                                                                                                  \n"," conv2d_117 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_113[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_117 (Batch  (None, 14, 14, 1024  4096       ['conv2d_117[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_37 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_117[0][0]',\n","                                )                                 'activation_111[0][0]']         \n","                                                                                                  \n"," activation_114 (Activation)    (None, 14, 14, 1024  0           ['add_37[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_118 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_114[0][0]']         \n","                                                                                                  \n"," batch_normalization_118 (Batch  (None, 14, 14, 256)  1024       ['conv2d_118[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_115 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_118[0][0]']\n","                                                                                                  \n"," conv2d_119 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_115[0][0]']         \n","                                                                                                  \n"," batch_normalization_119 (Batch  (None, 14, 14, 256)  1024       ['conv2d_119[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_116 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_119[0][0]']\n","                                                                                                  \n"," conv2d_120 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_116[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_120 (Batch  (None, 14, 14, 1024  4096       ['conv2d_120[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_38 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_120[0][0]',\n","                                )                                 'activation_114[0][0]']         \n","                                                                                                  \n"," activation_117 (Activation)    (None, 14, 14, 1024  0           ['add_38[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_121 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_117[0][0]']         \n","                                                                                                  \n"," batch_normalization_121 (Batch  (None, 14, 14, 256)  1024       ['conv2d_121[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_118 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_121[0][0]']\n","                                                                                                  \n"," conv2d_122 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_118[0][0]']         \n","                                                                                                  \n"," batch_normalization_122 (Batch  (None, 14, 14, 256)  1024       ['conv2d_122[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_119 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_122[0][0]']\n","                                                                                                  \n"," conv2d_123 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_119[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_123 (Batch  (None, 14, 14, 1024  4096       ['conv2d_123[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_39 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_123[0][0]',\n","                                )                                 'activation_117[0][0]']         \n","                                                                                                  \n"," activation_120 (Activation)    (None, 14, 14, 1024  0           ['add_39[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_124 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_120[0][0]']         \n","                                                                                                  \n"," batch_normalization_124 (Batch  (None, 14, 14, 256)  1024       ['conv2d_124[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_121 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_124[0][0]']\n","                                                                                                  \n"," conv2d_125 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_121[0][0]']         \n","                                                                                                  \n"," batch_normalization_125 (Batch  (None, 14, 14, 256)  1024       ['conv2d_125[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_122 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_125[0][0]']\n","                                                                                                  \n"," conv2d_126 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_122[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_126 (Batch  (None, 14, 14, 1024  4096       ['conv2d_126[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_40 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_126[0][0]',\n","                                )                                 'activation_120[0][0]']         \n","                                                                                                  \n"," activation_123 (Activation)    (None, 14, 14, 1024  0           ['add_40[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_127 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_123[0][0]']         \n","                                                                                                  \n"," batch_normalization_127 (Batch  (None, 14, 14, 256)  1024       ['conv2d_127[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_124 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_127[0][0]']\n","                                                                                                  \n"," conv2d_128 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_124[0][0]']         \n","                                                                                                  \n"," batch_normalization_128 (Batch  (None, 14, 14, 256)  1024       ['conv2d_128[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_125 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_128[0][0]']\n","                                                                                                  \n"," conv2d_129 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_125[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_129 (Batch  (None, 14, 14, 1024  4096       ['conv2d_129[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_41 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_129[0][0]',\n","                                )                                 'activation_123[0][0]']         \n","                                                                                                  \n"," activation_126 (Activation)    (None, 14, 14, 1024  0           ['add_41[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_130 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_126[0][0]']         \n","                                                                                                  \n"," batch_normalization_130 (Batch  (None, 14, 14, 256)  1024       ['conv2d_130[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_127 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_130[0][0]']\n","                                                                                                  \n"," conv2d_131 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_127[0][0]']         \n","                                                                                                  \n"," batch_normalization_131 (Batch  (None, 14, 14, 256)  1024       ['conv2d_131[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_128 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_131[0][0]']\n","                                                                                                  \n"," conv2d_132 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_128[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_132 (Batch  (None, 14, 14, 1024  4096       ['conv2d_132[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_42 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_132[0][0]',\n","                                )                                 'activation_126[0][0]']         \n","                                                                                                  \n"," activation_129 (Activation)    (None, 14, 14, 1024  0           ['add_42[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_133 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_129[0][0]']         \n","                                                                                                  \n"," batch_normalization_133 (Batch  (None, 14, 14, 256)  1024       ['conv2d_133[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_130 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_133[0][0]']\n","                                                                                                  \n"," conv2d_134 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_130[0][0]']         \n","                                                                                                  \n"," batch_normalization_134 (Batch  (None, 14, 14, 256)  1024       ['conv2d_134[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_131 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_134[0][0]']\n","                                                                                                  \n"," conv2d_135 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_131[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_135 (Batch  (None, 14, 14, 1024  4096       ['conv2d_135[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_43 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_135[0][0]',\n","                                )                                 'activation_129[0][0]']         \n","                                                                                                  \n"," activation_132 (Activation)    (None, 14, 14, 1024  0           ['add_43[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_136 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_132[0][0]']         \n","                                                                                                  \n"," batch_normalization_136 (Batch  (None, 14, 14, 256)  1024       ['conv2d_136[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_133 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_136[0][0]']\n","                                                                                                  \n"," conv2d_137 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_133[0][0]']         \n","                                                                                                  \n"," batch_normalization_137 (Batch  (None, 14, 14, 256)  1024       ['conv2d_137[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_134 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_137[0][0]']\n","                                                                                                  \n"," conv2d_138 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_134[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_138 (Batch  (None, 14, 14, 1024  4096       ['conv2d_138[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_44 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_138[0][0]',\n","                                )                                 'activation_132[0][0]']         \n","                                                                                                  \n"," activation_135 (Activation)    (None, 14, 14, 1024  0           ['add_44[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_139 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_135[0][0]']         \n","                                                                                                  \n"," batch_normalization_139 (Batch  (None, 14, 14, 256)  1024       ['conv2d_139[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_136 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_139[0][0]']\n","                                                                                                  \n"," conv2d_140 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_136[0][0]']         \n","                                                                                                  \n"," batch_normalization_140 (Batch  (None, 14, 14, 256)  1024       ['conv2d_140[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_137 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_140[0][0]']\n","                                                                                                  \n"," conv2d_141 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_137[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_141 (Batch  (None, 14, 14, 1024  4096       ['conv2d_141[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_45 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_141[0][0]',\n","                                )                                 'activation_135[0][0]']         \n","                                                                                                  \n"," activation_138 (Activation)    (None, 14, 14, 1024  0           ['add_45[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_142 (Conv2D)            (None, 14, 14, 256)  262400      ['activation_138[0][0]']         \n","                                                                                                  \n"," batch_normalization_142 (Batch  (None, 14, 14, 256)  1024       ['conv2d_142[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_139 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_142[0][0]']\n","                                                                                                  \n"," conv2d_143 (Conv2D)            (None, 14, 14, 256)  590080      ['activation_139[0][0]']         \n","                                                                                                  \n"," batch_normalization_143 (Batch  (None, 14, 14, 256)  1024       ['conv2d_143[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_140 (Activation)    (None, 14, 14, 256)  0           ['batch_normalization_143[0][0]']\n","                                                                                                  \n"," conv2d_144 (Conv2D)            (None, 14, 14, 1024  263168      ['activation_140[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_144 (Batch  (None, 14, 14, 1024  4096       ['conv2d_144[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," add_46 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_144[0][0]',\n","                                )                                 'activation_138[0][0]']         \n","                                                                                                  \n"," activation_141 (Activation)    (None, 14, 14, 1024  0           ['add_46[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_145 (Conv2D)            (None, 7, 7, 512)    524800      ['activation_141[0][0]']         \n","                                                                                                  \n"," batch_normalization_145 (Batch  (None, 7, 7, 512)   2048        ['conv2d_145[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_142 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_145[0][0]']\n","                                                                                                  \n"," conv2d_146 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_142[0][0]']         \n","                                                                                                  \n"," batch_normalization_146 (Batch  (None, 7, 7, 512)   2048        ['conv2d_146[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_143 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_146[0][0]']\n","                                                                                                  \n"," conv2d_147 (Conv2D)            (None, 7, 7, 2048)   1050624     ['activation_143[0][0]']         \n","                                                                                                  \n"," conv2d_148 (Conv2D)            (None, 7, 7, 2048)   2099200     ['activation_141[0][0]']         \n","                                                                                                  \n"," batch_normalization_147 (Batch  (None, 7, 7, 2048)  8192        ['conv2d_147[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," batch_normalization_148 (Batch  (None, 7, 7, 2048)  8192        ['conv2d_148[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," add_47 (Add)                   (None, 7, 7, 2048)   0           ['batch_normalization_147[0][0]',\n","                                                                  'batch_normalization_148[0][0]']\n","                                                                                                  \n"," activation_144 (Activation)    (None, 7, 7, 2048)   0           ['add_47[0][0]']                 \n","                                                                                                  \n"," conv2d_149 (Conv2D)            (None, 7, 7, 512)    1049088     ['activation_144[0][0]']         \n","                                                                                                  \n"," batch_normalization_149 (Batch  (None, 7, 7, 512)   2048        ['conv2d_149[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_145 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_149[0][0]']\n","                                                                                                  \n"," conv2d_150 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_145[0][0]']         \n","                                                                                                  \n"," batch_normalization_150 (Batch  (None, 7, 7, 512)   2048        ['conv2d_150[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_146 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_150[0][0]']\n","                                                                                                  \n"," conv2d_151 (Conv2D)            (None, 7, 7, 2048)   1050624     ['activation_146[0][0]']         \n","                                                                                                  \n"," batch_normalization_151 (Batch  (None, 7, 7, 2048)  8192        ['conv2d_151[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," add_48 (Add)                   (None, 7, 7, 2048)   0           ['batch_normalization_151[0][0]',\n","                                                                  'activation_144[0][0]']         \n","                                                                                                  \n"," activation_147 (Activation)    (None, 7, 7, 2048)   0           ['add_48[0][0]']                 \n","                                                                                                  \n"," conv2d_152 (Conv2D)            (None, 7, 7, 512)    1049088     ['activation_147[0][0]']         \n","                                                                                                  \n"," batch_normalization_152 (Batch  (None, 7, 7, 512)   2048        ['conv2d_152[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_148 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_152[0][0]']\n","                                                                                                  \n"," conv2d_153 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_148[0][0]']         \n","                                                                                                  \n"," batch_normalization_153 (Batch  (None, 7, 7, 512)   2048        ['conv2d_153[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_149 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_153[0][0]']\n","                                                                                                  \n"," conv2d_154 (Conv2D)            (None, 7, 7, 2048)   1050624     ['activation_149[0][0]']         \n","                                                                                                  \n"," batch_normalization_154 (Batch  (None, 7, 7, 2048)  8192        ['conv2d_154[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," add_49 (Add)                   (None, 7, 7, 2048)   0           ['batch_normalization_154[0][0]',\n","                                                                  'activation_147[0][0]']         \n","                                                                                                  \n"," activation_150 (Activation)    (None, 7, 7, 2048)   0           ['add_49[0][0]']                 \n","                                                                                                  \n"," average_pooling2d (AveragePool  (None, 4, 4, 2048)  0           ['activation_150[0][0]']         \n"," ing2D)                                                                                           \n","                                                                                                  \n"," flatten (Flatten)              (None, 32768)        0           ['average_pooling2d[0][0]']      \n","                                                                                                  \n"," dense (Dense)                  (None, 7)            229383      ['flatten[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 58,600,327\n","Trainable params: 58,448,903\n","Non-trainable params: 151,424\n","__________________________________________________________________________________________________\n"]}],"source":["from tensorflow.python.eager.context import set_log_device_placement\n","!pip install tensorflow-addons==0.16.1\n","import tensorflow_addons as tfa\n","\n","# Create the model\n","model = ResNet152(input_shape=(224 , 224, 3), classes=7)\n","# Establishes an exponential decay\n","lr_schedule = tf.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=0.00025,\n","    decay_steps=640,\n","    decay_rate=0.9\n",")\n","# Define an Adam optimizer\n","#adam = tfa.optimizers.AdamW(weight_decay=5e-4, learning_rate=lr_schedule)\n","adam = tf.optimizers.Adam(learning_rate=lr_schedule)\n","#sgd = tf.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True)\n","model.compile(optimizer=adam,\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"epa3q2hlamG-"},"id":"epa3q2hlamG-"},{"cell_type":"code","execution_count":null,"id":"da91c872","metadata":{"id":"da91c872","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd49d419-73c0-4169-922b-946936a1d427"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n","  warnings.warn('This ImageDataGenerator specifies '\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n","/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","64/64 [==============================] - 104s 1s/step - loss: 3.4405 - accuracy: 0.2513 - val_loss: 2.7798 - val_accuracy: 0.2491\n","Epoch 2/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.1851 - accuracy: 0.3215 - val_loss: 2.2829 - val_accuracy: 0.3527\n","Epoch 3/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.0140 - accuracy: 0.3806 - val_loss: 2.1882 - val_accuracy: 0.3415\n","Epoch 4/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.1209 - accuracy: 0.3975 - val_loss: 1.9905 - val_accuracy: 0.3515\n","Epoch 5/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.9402 - accuracy: 0.4191 - val_loss: 1.9405 - val_accuracy: 0.3780\n","Epoch 6/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6681 - accuracy: 0.4532 - val_loss: 1.9167 - val_accuracy: 0.3909\n","Epoch 7/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6858 - accuracy: 0.4566 - val_loss: 1.8015 - val_accuracy: 0.3832\n","Epoch 8/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.5224 - accuracy: 0.4714 - val_loss: 1.6734 - val_accuracy: 0.4094\n","Epoch 9/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.4561 - accuracy: 0.4892 - val_loss: 1.7924 - val_accuracy: 0.3816\n","Epoch 10/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.3616 - accuracy: 0.5141 - val_loss: 1.5425 - val_accuracy: 0.4665\n","Epoch 11/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.3055 - accuracy: 0.5159 - val_loss: 1.5965 - val_accuracy: 0.3909\n","Epoch 12/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2281 - accuracy: 0.5360 - val_loss: 1.5696 - val_accuracy: 0.4560\n","Epoch 13/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.1600 - accuracy: 0.5649 - val_loss: 1.4585 - val_accuracy: 0.4900\n","Epoch 14/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.1327 - accuracy: 0.5611 - val_loss: 1.5775 - val_accuracy: 0.4822\n","Epoch 15/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0759 - accuracy: 0.5809 - val_loss: 1.4540 - val_accuracy: 0.4380\n","Epoch 16/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0139 - accuracy: 0.5942 - val_loss: 1.5771 - val_accuracy: 0.4377\n","Epoch 17/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0016 - accuracy: 0.6103 - val_loss: 1.3614 - val_accuracy: 0.5031\n","Epoch 18/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.9809 - accuracy: 0.6101 - val_loss: 1.3838 - val_accuracy: 0.4918\n","Epoch 19/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.9329 - accuracy: 0.6334 - val_loss: 1.5691 - val_accuracy: 0.4480\n","Epoch 20/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.9206 - accuracy: 0.6314 - val_loss: 1.3166 - val_accuracy: 0.5085\n","Epoch 21/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.8750 - accuracy: 0.6408 - val_loss: 1.4554 - val_accuracy: 0.4647\n","Epoch 22/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.8444 - accuracy: 0.6506 - val_loss: 1.3629 - val_accuracy: 0.5262\n","Epoch 23/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.9217 - accuracy: 0.6361 - val_loss: 1.4595 - val_accuracy: 0.4662\n","Epoch 24/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.8784 - accuracy: 0.6457 - val_loss: 1.3587 - val_accuracy: 0.4892\n","Epoch 25/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.8649 - accuracy: 0.6562 - val_loss: 1.3448 - val_accuracy: 0.4992\n","Epoch 26/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.8052 - accuracy: 0.6763 - val_loss: 1.4010 - val_accuracy: 0.4732\n","Epoch 27/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.7989 - accuracy: 0.6687 - val_loss: 1.3395 - val_accuracy: 0.5087\n","Epoch 28/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.7606 - accuracy: 0.6955 - val_loss: 1.2522 - val_accuracy: 0.5512\n","Epoch 29/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.7607 - accuracy: 0.6996 - val_loss: 1.4730 - val_accuracy: 0.5101\n","Epoch 30/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.7266 - accuracy: 0.7018 - val_loss: 1.4844 - val_accuracy: 0.5175\n","Epoch 31/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.7219 - accuracy: 0.7089 - val_loss: 1.3526 - val_accuracy: 0.5237\n","Epoch 32/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6728 - accuracy: 0.7330 - val_loss: 1.3707 - val_accuracy: 0.5304\n","Epoch 33/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6823 - accuracy: 0.7298 - val_loss: 1.2355 - val_accuracy: 0.5414\n","Epoch 34/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6640 - accuracy: 0.7310 - val_loss: 1.3734 - val_accuracy: 0.5131\n","Epoch 35/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6800 - accuracy: 0.7325 - val_loss: 1.3310 - val_accuracy: 0.5163\n","Epoch 36/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6078 - accuracy: 0.7570 - val_loss: 1.3321 - val_accuracy: 0.5396\n","Epoch 37/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6772 - accuracy: 0.7283 - val_loss: 1.4880 - val_accuracy: 0.5237\n","Epoch 38/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6243 - accuracy: 0.7548 - val_loss: 1.5871 - val_accuracy: 0.4902\n","Epoch 39/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6201 - accuracy: 0.7592 - val_loss: 1.4284 - val_accuracy: 0.5358\n","Epoch 40/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6057 - accuracy: 0.7605 - val_loss: 1.4734 - val_accuracy: 0.5304\n","Epoch 41/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.5485 - accuracy: 0.7810 - val_loss: 1.7052 - val_accuracy: 0.5261\n","Epoch 42/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.5931 - accuracy: 0.7646 - val_loss: 1.3184 - val_accuracy: 0.5507\n","Epoch 43/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.6094 - accuracy: 0.7671 - val_loss: 1.3187 - val_accuracy: 0.5476\n","Epoch 44/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.5764 - accuracy: 0.7751 - val_loss: 1.3431 - val_accuracy: 0.5237\n","Epoch 45/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.5515 - accuracy: 0.7816 - val_loss: 1.5138 - val_accuracy: 0.5484\n","Epoch 46/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.5516 - accuracy: 0.7795 - val_loss: 1.2610 - val_accuracy: 0.5849\n","Epoch 47/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.5208 - accuracy: 0.7933 - val_loss: 1.4695 - val_accuracy: 0.5521\n","Epoch 48/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.4985 - accuracy: 0.8042 - val_loss: 1.5430 - val_accuracy: 0.5723\n","Epoch 49/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.5064 - accuracy: 0.8085 - val_loss: 1.3621 - val_accuracy: 0.5520\n","Epoch 50/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.4967 - accuracy: 0.8020 - val_loss: 1.3748 - val_accuracy: 0.5787\n","Epoch 51/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.4765 - accuracy: 0.8200 - val_loss: 1.5182 - val_accuracy: 0.5147\n","Epoch 52/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.4419 - accuracy: 0.8306 - val_loss: 1.3450 - val_accuracy: 0.5564\n","Epoch 53/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.4398 - accuracy: 0.8267 - val_loss: 1.4610 - val_accuracy: 0.5777\n","Epoch 54/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3962 - accuracy: 0.8458 - val_loss: 1.4339 - val_accuracy: 0.5834\n","Epoch 55/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3993 - accuracy: 0.8486 - val_loss: 1.5713 - val_accuracy: 0.5690\n","Epoch 56/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.4085 - accuracy: 0.8445 - val_loss: 1.4280 - val_accuracy: 0.5815\n","Epoch 57/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.4067 - accuracy: 0.8440 - val_loss: 1.5976 - val_accuracy: 0.5615\n","Epoch 58/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.4037 - accuracy: 0.8452 - val_loss: 1.4409 - val_accuracy: 0.5852\n","Epoch 59/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3496 - accuracy: 0.8624 - val_loss: 1.6633 - val_accuracy: 0.5627\n","Epoch 60/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3816 - accuracy: 0.8552 - val_loss: 1.4525 - val_accuracy: 0.5826\n","Epoch 61/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3372 - accuracy: 0.8740 - val_loss: 1.4453 - val_accuracy: 0.5867\n","Epoch 62/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3859 - accuracy: 0.8538 - val_loss: 1.5044 - val_accuracy: 0.5877\n","Epoch 63/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3366 - accuracy: 0.8780 - val_loss: 1.7896 - val_accuracy: 0.5762\n","Epoch 64/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3196 - accuracy: 0.8764 - val_loss: 1.5639 - val_accuracy: 0.5914\n","Epoch 65/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3499 - accuracy: 0.8623 - val_loss: 1.6063 - val_accuracy: 0.5611\n","Epoch 66/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2665 - accuracy: 0.8958 - val_loss: 1.5008 - val_accuracy: 0.5986\n","Epoch 67/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2981 - accuracy: 0.8840 - val_loss: 1.5642 - val_accuracy: 0.5757\n","Epoch 68/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3030 - accuracy: 0.8844 - val_loss: 1.5344 - val_accuracy: 0.5934\n","Epoch 69/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3503 - accuracy: 0.8656 - val_loss: 1.5682 - val_accuracy: 0.5646\n","Epoch 70/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3715 - accuracy: 0.8631 - val_loss: 1.6090 - val_accuracy: 0.5872\n","Epoch 71/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3371 - accuracy: 0.8784 - val_loss: 1.4571 - val_accuracy: 0.5952\n","Epoch 72/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3090 - accuracy: 0.8840 - val_loss: 1.4540 - val_accuracy: 0.6148\n","Epoch 73/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2858 - accuracy: 0.8915 - val_loss: 1.5047 - val_accuracy: 0.6016\n","Epoch 74/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2778 - accuracy: 0.8906 - val_loss: 1.5786 - val_accuracy: 0.5967\n","Epoch 75/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2777 - accuracy: 0.8952 - val_loss: 1.3431 - val_accuracy: 0.6112\n","Epoch 76/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2715 - accuracy: 0.9002 - val_loss: 1.5949 - val_accuracy: 0.5916\n","Epoch 77/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2303 - accuracy: 0.9144 - val_loss: 1.6300 - val_accuracy: 0.6001\n","Epoch 78/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2893 - accuracy: 0.8967 - val_loss: 1.3659 - val_accuracy: 0.6096\n","Epoch 79/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2261 - accuracy: 0.9174 - val_loss: 1.4725 - val_accuracy: 0.6300\n","Epoch 80/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2390 - accuracy: 0.9129 - val_loss: 1.5583 - val_accuracy: 0.6171\n","Epoch 81/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2076 - accuracy: 0.9210 - val_loss: 1.4035 - val_accuracy: 0.6426\n","Epoch 82/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3337 - accuracy: 0.8774 - val_loss: 1.3831 - val_accuracy: 0.5957\n","Epoch 83/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2338 - accuracy: 0.9119 - val_loss: 1.3825 - val_accuracy: 0.6380\n","Epoch 84/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1976 - accuracy: 0.9296 - val_loss: 1.5782 - val_accuracy: 0.6271\n","Epoch 85/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2272 - accuracy: 0.9171 - val_loss: 1.6597 - val_accuracy: 0.5947\n","Epoch 86/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.3226 - accuracy: 0.8838 - val_loss: 1.4055 - val_accuracy: 0.6138\n","Epoch 87/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2691 - accuracy: 0.9051 - val_loss: 1.5089 - val_accuracy: 0.6029\n","Epoch 88/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2416 - accuracy: 0.9097 - val_loss: 1.6164 - val_accuracy: 0.6094\n","Epoch 89/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2475 - accuracy: 0.9129 - val_loss: 1.5576 - val_accuracy: 0.6004\n","Epoch 90/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2030 - accuracy: 0.9227 - val_loss: 1.4033 - val_accuracy: 0.6413\n","Epoch 91/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1757 - accuracy: 0.9387 - val_loss: 1.5045 - val_accuracy: 0.6359\n","Epoch 92/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2033 - accuracy: 0.9267 - val_loss: 1.6093 - val_accuracy: 0.5934\n","Epoch 93/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2006 - accuracy: 0.9254 - val_loss: 1.4663 - val_accuracy: 0.6333\n","Epoch 94/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1632 - accuracy: 0.9424 - val_loss: 1.5417 - val_accuracy: 0.6155\n","Epoch 95/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1633 - accuracy: 0.9421 - val_loss: 1.6620 - val_accuracy: 0.6275\n","Epoch 96/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1887 - accuracy: 0.9328 - val_loss: 1.5312 - val_accuracy: 0.6366\n","Epoch 97/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1752 - accuracy: 0.9387 - val_loss: 1.3604 - val_accuracy: 0.6631\n","Epoch 98/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2061 - accuracy: 0.9239 - val_loss: 1.5346 - val_accuracy: 0.6068\n","Epoch 99/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1619 - accuracy: 0.9380 - val_loss: 1.5888 - val_accuracy: 0.6320\n","Epoch 100/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1747 - accuracy: 0.9413 - val_loss: 1.6113 - val_accuracy: 0.6248\n","Epoch 101/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1573 - accuracy: 0.9394 - val_loss: 1.7406 - val_accuracy: 0.6066\n","Epoch 102/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1737 - accuracy: 0.9377 - val_loss: 1.7197 - val_accuracy: 0.6089\n","Epoch 103/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1849 - accuracy: 0.9360 - val_loss: 1.3805 - val_accuracy: 0.6302\n","Epoch 104/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2062 - accuracy: 0.9286 - val_loss: 1.5002 - val_accuracy: 0.6264\n","Epoch 105/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1458 - accuracy: 0.9465 - val_loss: 1.6065 - val_accuracy: 0.6328\n","Epoch 106/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1398 - accuracy: 0.9507 - val_loss: 1.5905 - val_accuracy: 0.6441\n","Epoch 107/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1425 - accuracy: 0.9473 - val_loss: 1.7570 - val_accuracy: 0.6161\n","Epoch 108/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1481 - accuracy: 0.9470 - val_loss: 1.5425 - val_accuracy: 0.6336\n","Epoch 109/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1730 - accuracy: 0.9365 - val_loss: 1.6569 - val_accuracy: 0.6096\n","Epoch 110/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1368 - accuracy: 0.9534 - val_loss: 1.5089 - val_accuracy: 0.6432\n","Epoch 111/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.2464 - accuracy: 0.9203 - val_loss: 1.4626 - val_accuracy: 0.6153\n","Epoch 112/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1264 - accuracy: 0.9586 - val_loss: 1.5795 - val_accuracy: 0.6390\n","Epoch 113/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1194 - accuracy: 0.9563 - val_loss: 1.6744 - val_accuracy: 0.6349\n","Epoch 114/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1524 - accuracy: 0.9409 - val_loss: 1.5664 - val_accuracy: 0.6245\n","Epoch 115/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1241 - accuracy: 0.9546 - val_loss: 1.7303 - val_accuracy: 0.6279\n","Epoch 116/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1669 - accuracy: 0.9411 - val_loss: 1.5485 - val_accuracy: 0.6254\n","Epoch 117/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1120 - accuracy: 0.9593 - val_loss: 1.5718 - val_accuracy: 0.6420\n","Epoch 118/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1159 - accuracy: 0.9612 - val_loss: 1.5781 - val_accuracy: 0.6539\n","Epoch 119/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1369 - accuracy: 0.9505 - val_loss: 1.5116 - val_accuracy: 0.6362\n","Epoch 120/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0843 - accuracy: 0.9703 - val_loss: 1.5279 - val_accuracy: 0.6637\n","Epoch 121/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1003 - accuracy: 0.9662 - val_loss: 1.6613 - val_accuracy: 0.6256\n","Epoch 122/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1196 - accuracy: 0.9603 - val_loss: 1.5754 - val_accuracy: 0.6324\n","Epoch 123/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1170 - accuracy: 0.9600 - val_loss: 1.4983 - val_accuracy: 0.6549\n","Epoch 124/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1299 - accuracy: 0.9561 - val_loss: 1.5061 - val_accuracy: 0.6405\n","Epoch 125/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1125 - accuracy: 0.9602 - val_loss: 1.5735 - val_accuracy: 0.6342\n","Epoch 126/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0862 - accuracy: 0.9686 - val_loss: 1.4511 - val_accuracy: 0.6750\n","Epoch 127/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1186 - accuracy: 0.9603 - val_loss: 1.5240 - val_accuracy: 0.6382\n","Epoch 128/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1140 - accuracy: 0.9585 - val_loss: 1.5031 - val_accuracy: 0.6434\n","Epoch 129/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1124 - accuracy: 0.9588 - val_loss: 1.6945 - val_accuracy: 0.6227\n","Epoch 130/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1233 - accuracy: 0.9588 - val_loss: 1.5521 - val_accuracy: 0.6462\n","Epoch 131/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0990 - accuracy: 0.9652 - val_loss: 1.7095 - val_accuracy: 0.6432\n","Epoch 132/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0992 - accuracy: 0.9640 - val_loss: 1.6214 - val_accuracy: 0.6462\n","Epoch 133/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0898 - accuracy: 0.9664 - val_loss: 1.7533 - val_accuracy: 0.6547\n","Epoch 134/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0936 - accuracy: 0.9676 - val_loss: 1.6933 - val_accuracy: 0.6468\n","Epoch 135/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0906 - accuracy: 0.9701 - val_loss: 1.7296 - val_accuracy: 0.6495\n","Epoch 136/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1383 - accuracy: 0.9517 - val_loss: 1.7276 - val_accuracy: 0.6207\n","Epoch 137/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1071 - accuracy: 0.9613 - val_loss: 1.6150 - val_accuracy: 0.6592\n","Epoch 138/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0746 - accuracy: 0.9750 - val_loss: 1.7570 - val_accuracy: 0.6410\n","Epoch 139/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1286 - accuracy: 0.9603 - val_loss: 1.6582 - val_accuracy: 0.6397\n","Epoch 140/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0676 - accuracy: 0.9764 - val_loss: 1.5917 - val_accuracy: 0.6612\n","Epoch 141/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0610 - accuracy: 0.9769 - val_loss: 1.8493 - val_accuracy: 0.6377\n","Epoch 142/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0880 - accuracy: 0.9679 - val_loss: 1.7660 - val_accuracy: 0.6503\n","Epoch 143/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0686 - accuracy: 0.9764 - val_loss: 1.8238 - val_accuracy: 0.6646\n","Epoch 144/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0781 - accuracy: 0.9698 - val_loss: 1.7583 - val_accuracy: 0.6652\n","Epoch 145/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0754 - accuracy: 0.9752 - val_loss: 1.6457 - val_accuracy: 0.6608\n","Epoch 146/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0825 - accuracy: 0.9725 - val_loss: 1.7882 - val_accuracy: 0.6424\n","Epoch 147/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1106 - accuracy: 0.9603 - val_loss: 1.5845 - val_accuracy: 0.6696\n","Epoch 148/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0850 - accuracy: 0.9740 - val_loss: 1.5618 - val_accuracy: 0.6665\n","Epoch 149/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0492 - accuracy: 0.9833 - val_loss: 1.7777 - val_accuracy: 0.6631\n","Epoch 150/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0873 - accuracy: 0.9696 - val_loss: 1.6473 - val_accuracy: 0.6475\n","Epoch 151/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 1.6731 - val_accuracy: 0.6686\n","Epoch 152/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0770 - accuracy: 0.9740 - val_loss: 1.7184 - val_accuracy: 0.6558\n","Epoch 153/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0662 - accuracy: 0.9779 - val_loss: 1.7268 - val_accuracy: 0.6562\n","Epoch 154/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0693 - accuracy: 0.9743 - val_loss: 1.8014 - val_accuracy: 0.6601\n","Epoch 155/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.1043 - accuracy: 0.9649 - val_loss: 1.5481 - val_accuracy: 0.6437\n","Epoch 156/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 1.6905 - val_accuracy: 0.6552\n","Epoch 157/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 1.6037 - val_accuracy: 0.6727\n","Epoch 158/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0720 - accuracy: 0.9769 - val_loss: 1.6500 - val_accuracy: 0.6736\n","Epoch 159/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0895 - accuracy: 0.9713 - val_loss: 1.5026 - val_accuracy: 0.6863\n","Epoch 160/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0791 - accuracy: 0.9723 - val_loss: 1.6751 - val_accuracy: 0.6737\n","Epoch 161/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0536 - accuracy: 0.9801 - val_loss: 1.8535 - val_accuracy: 0.6491\n","Epoch 162/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0608 - accuracy: 0.9787 - val_loss: 1.6956 - val_accuracy: 0.6642\n","Epoch 163/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0812 - accuracy: 0.9740 - val_loss: 1.5631 - val_accuracy: 0.6724\n","Epoch 164/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 1.9115 - val_accuracy: 0.6522\n","Epoch 165/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 1.7368 - val_accuracy: 0.6650\n","Epoch 166/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0556 - accuracy: 0.9804 - val_loss: 1.9578 - val_accuracy: 0.6631\n","Epoch 167/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0760 - accuracy: 0.9747 - val_loss: 1.8582 - val_accuracy: 0.6411\n","Epoch 168/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0796 - accuracy: 0.9737 - val_loss: 1.5659 - val_accuracy: 0.6863\n","Epoch 169/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0476 - accuracy: 0.9823 - val_loss: 1.6295 - val_accuracy: 0.6840\n","Epoch 170/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0623 - accuracy: 0.9777 - val_loss: 1.7537 - val_accuracy: 0.6494\n","Epoch 171/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0371 - accuracy: 0.9850 - val_loss: 2.0040 - val_accuracy: 0.6513\n","Epoch 172/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0520 - accuracy: 0.9828 - val_loss: 1.7210 - val_accuracy: 0.6737\n","Epoch 173/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 1.6694 - val_accuracy: 0.6840\n","Epoch 174/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 1.6059 - val_accuracy: 0.6845\n","Epoch 175/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0501 - accuracy: 0.9838 - val_loss: 1.8559 - val_accuracy: 0.6523\n","Epoch 176/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0380 - accuracy: 0.9868 - val_loss: 1.8173 - val_accuracy: 0.6858\n","Epoch 177/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0397 - accuracy: 0.9892 - val_loss: 1.6820 - val_accuracy: 0.6879\n","Epoch 178/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 1.7889 - val_accuracy: 0.6657\n","Epoch 179/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 1.9054 - val_accuracy: 0.6623\n","Epoch 180/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0585 - accuracy: 0.9791 - val_loss: 1.9003 - val_accuracy: 0.6364\n","Epoch 181/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0514 - accuracy: 0.9848 - val_loss: 1.9061 - val_accuracy: 0.6585\n","Epoch 182/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 1.7987 - val_accuracy: 0.6788\n","Epoch 183/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 1.7413 - val_accuracy: 0.6781\n","Epoch 184/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0513 - accuracy: 0.9809 - val_loss: 1.8788 - val_accuracy: 0.6662\n","Epoch 185/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0283 - accuracy: 0.9887 - val_loss: 1.8834 - val_accuracy: 0.6600\n","Epoch 186/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 2.1207 - val_accuracy: 0.6521\n","Epoch 187/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0466 - accuracy: 0.9848 - val_loss: 1.8508 - val_accuracy: 0.6660\n","Epoch 188/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 1.8867 - val_accuracy: 0.6749\n","Epoch 189/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0382 - accuracy: 0.9877 - val_loss: 1.7788 - val_accuracy: 0.6956\n","Epoch 190/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0480 - accuracy: 0.9850 - val_loss: 2.1412 - val_accuracy: 0.6459\n","Epoch 191/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0505 - accuracy: 0.9814 - val_loss: 1.7537 - val_accuracy: 0.6631\n","Epoch 192/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 1.9507 - val_accuracy: 0.6616\n","Epoch 193/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0470 - accuracy: 0.9838 - val_loss: 2.0479 - val_accuracy: 0.6287\n","Epoch 194/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0242 - accuracy: 0.9914 - val_loss: 1.9043 - val_accuracy: 0.6587\n","Epoch 195/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 1.9148 - val_accuracy: 0.6598\n","Epoch 196/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0366 - accuracy: 0.9875 - val_loss: 1.9291 - val_accuracy: 0.6693\n","Epoch 197/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 1.9378 - val_accuracy: 0.6674\n","Epoch 198/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0411 - accuracy: 0.9872 - val_loss: 1.9796 - val_accuracy: 0.6711\n","Epoch 199/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0273 - accuracy: 0.9890 - val_loss: 1.9326 - val_accuracy: 0.6747\n","Epoch 200/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0524 - accuracy: 0.9806 - val_loss: 1.8066 - val_accuracy: 0.6716\n","Epoch 201/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0431 - accuracy: 0.9831 - val_loss: 1.5323 - val_accuracy: 0.6994\n","Epoch 202/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 1.7902 - val_accuracy: 0.6866\n","Epoch 203/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 1.8337 - val_accuracy: 0.6868\n","Epoch 204/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 1.6429 - val_accuracy: 0.7087\n","Epoch 205/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 1.9465 - val_accuracy: 0.6835\n","Epoch 206/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0278 - accuracy: 0.9892 - val_loss: 2.0399 - val_accuracy: 0.6584\n","Epoch 207/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 1.8372 - val_accuracy: 0.6760\n","Epoch 208/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0286 - accuracy: 0.9919 - val_loss: 1.7736 - val_accuracy: 0.6773\n","Epoch 209/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 1.9557 - val_accuracy: 0.6729\n","Epoch 210/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 1.8057 - val_accuracy: 0.6853\n","Epoch 211/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 1.9456 - val_accuracy: 0.6722\n","Epoch 212/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0391 - accuracy: 0.9877 - val_loss: 1.7648 - val_accuracy: 0.6840\n","Epoch 213/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 1.8169 - val_accuracy: 0.6768\n","Epoch 214/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 1.9329 - val_accuracy: 0.6745\n","Epoch 215/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 1.8631 - val_accuracy: 0.6716\n","Epoch 216/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 2.0293 - val_accuracy: 0.6650\n","Epoch 217/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 1.8108 - val_accuracy: 0.6894\n","Epoch 218/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 1.8920 - val_accuracy: 0.6726\n","Epoch 219/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0329 - accuracy: 0.9880 - val_loss: 1.9648 - val_accuracy: 0.6819\n","Epoch 220/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 1.8160 - val_accuracy: 0.6806\n","Epoch 221/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 1.8159 - val_accuracy: 0.6716\n","Epoch 222/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 2.0853 - val_accuracy: 0.6837\n","Epoch 223/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 2.0741 - val_accuracy: 0.6742\n","Epoch 224/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 1.8946 - val_accuracy: 0.6845\n","Epoch 225/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 2.0614 - val_accuracy: 0.6613\n","Epoch 226/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 2.0589 - val_accuracy: 0.6788\n","Epoch 227/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 2.1559 - val_accuracy: 0.6638\n","Epoch 228/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 1.9729 - val_accuracy: 0.6768\n","Epoch 229/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 1.8566 - val_accuracy: 0.6824\n","Epoch 230/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 1.8929 - val_accuracy: 0.6863\n","Epoch 231/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0166 - accuracy: 0.9936 - val_loss: 1.8931 - val_accuracy: 0.6951\n","Epoch 232/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 1.8757 - val_accuracy: 0.6940\n","Epoch 233/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 2.0468 - val_accuracy: 0.6842\n","Epoch 234/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 1.7913 - val_accuracy: 0.6963\n","Epoch 235/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 2.0349 - val_accuracy: 0.6655\n","Epoch 236/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 1.8520 - val_accuracy: 0.6860\n","Epoch 237/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 1.8296 - val_accuracy: 0.6958\n","Epoch 238/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 1.8846 - val_accuracy: 0.7036\n","Epoch 239/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 2.1427 - val_accuracy: 0.6811\n","Epoch 240/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 1.9331 - val_accuracy: 0.6729\n","Epoch 241/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.9033 - val_accuracy: 0.6891\n","Epoch 242/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 2.1535 - val_accuracy: 0.6899\n","Epoch 243/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 2.1117 - val_accuracy: 0.6897\n","Epoch 244/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 1.8458 - val_accuracy: 0.6930\n","Epoch 245/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0092 - accuracy: 0.9961 - val_loss: 1.9843 - val_accuracy: 0.6850\n","Epoch 246/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 2.1205 - val_accuracy: 0.6840\n","Epoch 247/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 2.0609 - val_accuracy: 0.6809\n","Epoch 248/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0259 - accuracy: 0.9939 - val_loss: 2.0141 - val_accuracy: 0.6832\n","Epoch 249/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 2.1571 - val_accuracy: 0.6680\n","Epoch 250/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 2.1196 - val_accuracy: 0.6863\n","Epoch 251/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 1.9064 - val_accuracy: 0.7005\n","Epoch 252/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 1.9991 - val_accuracy: 0.7020\n","Epoch 253/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 2.1140 - val_accuracy: 0.6863\n","Epoch 254/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 2.3175 - val_accuracy: 0.6708\n","Epoch 255/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 2.0521 - val_accuracy: 0.6969\n","Epoch 256/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 2.1637 - val_accuracy: 0.6871\n","Epoch 257/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 2.1315 - val_accuracy: 0.6816\n","Epoch 258/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 2.0985 - val_accuracy: 0.6879\n","Epoch 259/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.9883 - val_accuracy: 0.6969\n","Epoch 260/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0132 - accuracy: 0.9948 - val_loss: 1.9318 - val_accuracy: 0.6966\n","Epoch 261/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 1.9241 - val_accuracy: 0.6958\n","Epoch 262/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 2.0702 - val_accuracy: 0.6719\n","Epoch 263/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 2.1851 - val_accuracy: 0.6747\n","Epoch 264/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 2.1315 - val_accuracy: 0.6843\n","Epoch 265/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 1.9398 - val_accuracy: 0.6881\n","Epoch 266/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 1.9432 - val_accuracy: 0.6775\n","Epoch 267/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 1.9134 - val_accuracy: 0.6956\n","Epoch 268/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.8982 - val_accuracy: 0.7036\n","Epoch 269/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.9520 - val_accuracy: 0.6863\n","Epoch 270/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 2.0265 - val_accuracy: 0.6917\n","Epoch 271/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 1.9332 - val_accuracy: 0.6879\n","Epoch 272/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 2.0391 - val_accuracy: 0.6961\n","Epoch 273/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 1.9536 - val_accuracy: 0.6845\n","Epoch 274/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 1.8888 - val_accuracy: 0.6912\n","Epoch 275/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.9281 - val_accuracy: 0.7038\n","Epoch 276/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 2.0363 - val_accuracy: 0.6835\n","Epoch 277/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 2.1113 - val_accuracy: 0.6871\n","Epoch 278/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 2.1791 - val_accuracy: 0.6765\n","Epoch 279/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 1.9986 - val_accuracy: 0.6933\n","Epoch 280/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 2.0336 - val_accuracy: 0.6999\n","Epoch 281/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 2.0274 - val_accuracy: 0.7036\n","Epoch 282/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 2.0047 - val_accuracy: 0.6930\n","Epoch 283/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 2.1356 - val_accuracy: 0.6871\n","Epoch 284/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0085 - accuracy: 0.9961 - val_loss: 2.1587 - val_accuracy: 0.6868\n","Epoch 285/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0055 - accuracy: 0.9978 - val_loss: 2.0565 - val_accuracy: 0.6879\n","Epoch 286/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 2.1215 - val_accuracy: 0.6922\n","Epoch 287/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 2.2048 - val_accuracy: 0.6842\n","Epoch 288/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 2.1866 - val_accuracy: 0.6922\n","Epoch 289/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 2.1851 - val_accuracy: 0.6801\n","Epoch 290/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 2.0792 - val_accuracy: 0.7020\n","Epoch 291/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 1.9976 - val_accuracy: 0.6953\n","Epoch 292/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 2.2278 - val_accuracy: 0.6791\n","Epoch 293/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 2.2170 - val_accuracy: 0.6945\n","Epoch 294/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 2.1212 - val_accuracy: 0.6866\n","Epoch 295/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 2.1577 - val_accuracy: 0.6897\n","Epoch 296/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 2.1357 - val_accuracy: 0.6943\n","Epoch 297/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 2.0853 - val_accuracy: 0.6961\n","Epoch 298/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0063 - accuracy: 0.9973 - val_loss: 2.2114 - val_accuracy: 0.6976\n","Epoch 299/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 2.2013 - val_accuracy: 0.6935\n","Epoch 300/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 2.2517 - val_accuracy: 0.6891\n","Epoch 301/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 2.3382 - val_accuracy: 0.6858\n","Epoch 302/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0078 - accuracy: 0.9963 - val_loss: 2.1275 - val_accuracy: 0.7085\n","Epoch 303/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 2.1430 - val_accuracy: 0.7110\n","Epoch 304/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 2.2398 - val_accuracy: 0.6945\n","Epoch 305/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.3469 - val_accuracy: 0.6803\n","Epoch 306/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 2.2677 - val_accuracy: 0.6809\n","Epoch 307/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 2.3128 - val_accuracy: 0.6884\n","Epoch 308/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.2321 - val_accuracy: 0.6896\n","Epoch 309/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 2.3393 - val_accuracy: 0.6922\n","Epoch 310/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 2.2475 - val_accuracy: 0.7082\n","Epoch 311/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 2.2786 - val_accuracy: 0.6992\n","Epoch 312/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 2.3610 - val_accuracy: 0.6897\n","Epoch 313/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 2.3552 - val_accuracy: 0.6817\n","Epoch 314/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 2.3722 - val_accuracy: 0.6870\n","Epoch 315/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 2.2585 - val_accuracy: 0.6938\n","Epoch 316/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 2.2478 - val_accuracy: 0.6907\n","Epoch 317/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 2.2601 - val_accuracy: 0.6979\n","Epoch 318/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 2.3880 - val_accuracy: 0.6845\n","Epoch 319/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 2.3121 - val_accuracy: 0.6871\n","Epoch 320/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 2.2940 - val_accuracy: 0.6999\n","Epoch 321/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 2.2613 - val_accuracy: 0.6999\n","Epoch 322/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 2.2242 - val_accuracy: 0.6989\n","Epoch 323/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 2.2941 - val_accuracy: 0.6976\n","Epoch 324/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 2.2815 - val_accuracy: 0.6994\n","Epoch 325/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 2.2345 - val_accuracy: 0.6922\n","Epoch 326/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 2.1798 - val_accuracy: 0.6969\n","Epoch 327/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 2.2224 - val_accuracy: 0.7025\n","Epoch 328/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 2.0670 - val_accuracy: 0.7051\n","Epoch 329/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 2.2014 - val_accuracy: 0.7007\n","Epoch 330/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 2.2024 - val_accuracy: 0.6886\n","Epoch 331/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 2.2668 - val_accuracy: 0.6855\n","Epoch 332/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 2.1594 - val_accuracy: 0.6966\n","Epoch 333/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 2.0719 - val_accuracy: 0.7177\n","Epoch 334/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 2.1677 - val_accuracy: 0.6912\n","Epoch 335/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 2.2089 - val_accuracy: 0.6914\n","Epoch 336/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 2.1921 - val_accuracy: 0.7054\n","Epoch 337/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.0750e-04 - accuracy: 0.9998 - val_loss: 2.0582 - val_accuracy: 0.7154\n","Epoch 338/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 2.1299 - val_accuracy: 0.7041\n","Epoch 339/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 2.2471 - val_accuracy: 0.7017\n","Epoch 340/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 2.2963 - val_accuracy: 0.6915\n","Epoch 341/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.2930 - val_accuracy: 0.7012\n","Epoch 342/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 2.0799 - val_accuracy: 0.7133\n","Epoch 343/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.2173 - val_accuracy: 0.7061\n","Epoch 344/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 2.2126 - val_accuracy: 0.6999\n","Epoch 345/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 2.3821 - val_accuracy: 0.6994\n","Epoch 346/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.3255 - val_accuracy: 0.7007\n","Epoch 347/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 2.3215 - val_accuracy: 0.6979\n","Epoch 348/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 2.3001 - val_accuracy: 0.6981\n","Epoch 349/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 2.2373 - val_accuracy: 0.7041\n","Epoch 350/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 2.3096 - val_accuracy: 0.6992\n","Epoch 351/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 2.3401 - val_accuracy: 0.6945\n","Epoch 352/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.3912 - val_accuracy: 0.6969\n","Epoch 353/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 2.4058 - val_accuracy: 0.6966\n","Epoch 354/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.3641 - val_accuracy: 0.6969\n","Epoch 355/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 2.4947 - val_accuracy: 0.6915\n","Epoch 356/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 2.3797 - val_accuracy: 0.7025\n","Epoch 357/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 2.3757 - val_accuracy: 0.7010\n","Epoch 358/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 2.4330 - val_accuracy: 0.6935\n","Epoch 359/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 2.4298 - val_accuracy: 0.6925\n","Epoch 360/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 2.3128 - val_accuracy: 0.6879\n","Epoch 361/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 2.4193 - val_accuracy: 0.6832\n","Epoch 362/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 2.4931 - val_accuracy: 0.6842\n","Epoch 363/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 2.4720 - val_accuracy: 0.6935\n","Epoch 364/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 2.5696 - val_accuracy: 0.6801\n","Epoch 365/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 2.4382 - val_accuracy: 0.6829\n","Epoch 366/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 2.5584 - val_accuracy: 0.6824\n","Epoch 367/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 2.4578 - val_accuracy: 0.6886\n","Epoch 368/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 2.3560 - val_accuracy: 0.6994\n","Epoch 369/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.5291 - val_accuracy: 0.6791\n","Epoch 370/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 2.3731 - val_accuracy: 0.6891\n","Epoch 371/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 2.5370 - val_accuracy: 0.6798\n","Epoch 372/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 2.5531 - val_accuracy: 0.6709\n","Epoch 373/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 2.4282 - val_accuracy: 0.6858\n","Epoch 374/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 2.3078 - val_accuracy: 0.6969\n","Epoch 375/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 2.3167 - val_accuracy: 0.6925\n","Epoch 376/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 2.3865 - val_accuracy: 0.7005\n","Epoch 377/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 2.4350 - val_accuracy: 0.6935\n","Epoch 378/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 2.3372 - val_accuracy: 0.6948\n","Epoch 379/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 2.3043 - val_accuracy: 0.7079\n","Epoch 380/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.7580e-04 - accuracy: 1.0000 - val_loss: 2.3617 - val_accuracy: 0.7051\n","Epoch 381/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.0679e-04 - accuracy: 0.9998 - val_loss: 2.3157 - val_accuracy: 0.7025\n","Epoch 382/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 2.4780 - val_accuracy: 0.6966\n","Epoch 383/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 2.3236 - val_accuracy: 0.7051\n","Epoch 384/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 2.3296 - val_accuracy: 0.7066\n","Epoch 385/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 2.4201 - val_accuracy: 0.6976\n","Epoch 386/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 2.3524 - val_accuracy: 0.7074\n","Epoch 387/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.7881e-04 - accuracy: 1.0000 - val_loss: 2.3142 - val_accuracy: 0.7051\n","Epoch 388/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.0963e-04 - accuracy: 0.9998 - val_loss: 2.3465 - val_accuracy: 0.7054\n","Epoch 389/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.3182 - val_accuracy: 0.7090\n","Epoch 390/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.7589e-04 - accuracy: 0.9998 - val_loss: 2.3442 - val_accuracy: 0.7162\n","Epoch 391/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 2.3237 - val_accuracy: 0.7036\n","Epoch 392/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 2.4083 - val_accuracy: 0.7090\n","Epoch 393/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.4017 - val_accuracy: 0.7059\n","Epoch 394/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 2.4560 - val_accuracy: 0.7043\n","Epoch 395/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.2515e-04 - accuracy: 1.0000 - val_loss: 2.4538 - val_accuracy: 0.7023\n","Epoch 396/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 2.5549 - val_accuracy: 0.6981\n","Epoch 397/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.5936 - val_accuracy: 0.7012\n","Epoch 398/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 2.6707 - val_accuracy: 0.6868\n","Epoch 399/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.5919 - val_accuracy: 0.6943\n","Epoch 400/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.9747e-04 - accuracy: 0.9998 - val_loss: 2.4933 - val_accuracy: 0.6979\n","Epoch 401/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.6270e-04 - accuracy: 1.0000 - val_loss: 2.5542 - val_accuracy: 0.6912\n","Epoch 402/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 2.5186 - val_accuracy: 0.6984\n","Epoch 403/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.0868e-04 - accuracy: 0.9998 - val_loss: 2.4944 - val_accuracy: 0.6938\n","Epoch 404/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.1170e-04 - accuracy: 0.9998 - val_loss: 2.5623 - val_accuracy: 0.7005\n","Epoch 405/1000\n","64/64 [==============================] - 66s 1s/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 2.6018 - val_accuracy: 0.6992\n","Epoch 406/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 2.5847 - val_accuracy: 0.6827\n","Epoch 407/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 2.5609 - val_accuracy: 0.6873\n","Epoch 408/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0029 - accuracy: 0.9983 - val_loss: 2.4051 - val_accuracy: 0.7072\n","Epoch 409/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 2.5409 - val_accuracy: 0.6953\n","Epoch 410/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0025 - accuracy: 0.9985 - val_loss: 2.5907 - val_accuracy: 0.6912\n","Epoch 411/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 2.5502 - val_accuracy: 0.6922\n","Epoch 412/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 2.6199 - val_accuracy: 0.6873\n","Epoch 413/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.7370 - val_accuracy: 0.6811\n","Epoch 414/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 2.5849 - val_accuracy: 0.6927\n","Epoch 415/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 2.5970 - val_accuracy: 0.6917\n","Epoch 416/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.4265e-04 - accuracy: 1.0000 - val_loss: 2.4498 - val_accuracy: 0.6969\n","Epoch 417/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 2.5096 - val_accuracy: 0.7002\n","Epoch 418/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.5160 - val_accuracy: 0.6979\n","Epoch 419/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 2.5456 - val_accuracy: 0.6994\n","Epoch 420/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 2.5670 - val_accuracy: 0.6992\n","Epoch 421/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 2.5272 - val_accuracy: 0.6971\n","Epoch 422/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.6062e-04 - accuracy: 1.0000 - val_loss: 2.7703 - val_accuracy: 0.6896\n","Epoch 423/1000\n","64/64 [==============================] - 66s 1s/step - loss: 8.4633e-04 - accuracy: 0.9998 - val_loss: 2.6199 - val_accuracy: 0.6963\n","Epoch 424/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.4030e-04 - accuracy: 0.9998 - val_loss: 2.5144 - val_accuracy: 0.6981\n","Epoch 425/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.3572e-04 - accuracy: 1.0000 - val_loss: 2.5295 - val_accuracy: 0.6994\n","Epoch 426/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.8457e-04 - accuracy: 0.9998 - val_loss: 2.5503 - val_accuracy: 0.6997\n","Epoch 427/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 2.5318 - val_accuracy: 0.7030\n","Epoch 428/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 2.4538 - val_accuracy: 0.6992\n","Epoch 429/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 2.3589 - val_accuracy: 0.7061\n","Epoch 430/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 2.4115 - val_accuracy: 0.7169\n","Epoch 431/1000\n","64/64 [==============================] - 66s 1s/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 2.5629 - val_accuracy: 0.7010\n","Epoch 432/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.4407 - val_accuracy: 0.7131\n","Epoch 433/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.4072 - val_accuracy: 0.7007\n","Epoch 434/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.1919e-04 - accuracy: 1.0000 - val_loss: 2.4886 - val_accuracy: 0.7100\n","Epoch 435/1000\n","64/64 [==============================] - 66s 1s/step - loss: 7.9767e-04 - accuracy: 0.9995 - val_loss: 2.5271 - val_accuracy: 0.7074\n","Epoch 436/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.8662e-04 - accuracy: 0.9998 - val_loss: 2.5995 - val_accuracy: 0.7028\n","Epoch 437/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 2.4035 - val_accuracy: 0.7043\n","Epoch 438/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.0257e-04 - accuracy: 1.0000 - val_loss: 2.4700 - val_accuracy: 0.7113\n","Epoch 439/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 2.4906 - val_accuracy: 0.7097\n","Epoch 440/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.6295 - val_accuracy: 0.7007\n","Epoch 441/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 2.6002 - val_accuracy: 0.6961\n","Epoch 442/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 2.7203 - val_accuracy: 0.6909\n","Epoch 443/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.6991 - val_accuracy: 0.6987\n","Epoch 444/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.0290e-04 - accuracy: 0.9995 - val_loss: 2.6693 - val_accuracy: 0.6897\n","Epoch 445/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.8278e-04 - accuracy: 0.9998 - val_loss: 2.7101 - val_accuracy: 0.6945\n","Epoch 446/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.4212e-04 - accuracy: 1.0000 - val_loss: 2.7552 - val_accuracy: 0.6981\n","Epoch 447/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.5186e-04 - accuracy: 0.9998 - val_loss: 2.7981 - val_accuracy: 0.6876\n","Epoch 448/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 2.6656 - val_accuracy: 0.6958\n","Epoch 449/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.3864e-04 - accuracy: 0.9993 - val_loss: 2.6343 - val_accuracy: 0.7038\n","Epoch 450/1000\n","64/64 [==============================] - 66s 1s/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 2.6296 - val_accuracy: 0.6951\n","Epoch 451/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 2.7234 - val_accuracy: 0.6922\n","Epoch 452/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.8846e-04 - accuracy: 0.9998 - val_loss: 2.7087 - val_accuracy: 0.7015\n","Epoch 453/1000\n","64/64 [==============================] - 66s 1s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.7738 - val_accuracy: 0.7015\n","Epoch 454/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.6092 - val_accuracy: 0.6971\n","Epoch 455/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.5781 - val_accuracy: 0.7087\n","Epoch 456/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.0596e-04 - accuracy: 1.0000 - val_loss: 2.7183 - val_accuracy: 0.7020\n","Epoch 457/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.6097 - val_accuracy: 0.7005\n","Epoch 458/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.7837e-04 - accuracy: 1.0000 - val_loss: 2.6412 - val_accuracy: 0.6935\n","Epoch 459/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.1555e-04 - accuracy: 1.0000 - val_loss: 2.6597 - val_accuracy: 0.6917\n","Epoch 460/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.4113e-04 - accuracy: 1.0000 - val_loss: 2.6044 - val_accuracy: 0.7072\n","Epoch 461/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 2.7683 - val_accuracy: 0.6886\n","Epoch 462/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 2.7038 - val_accuracy: 0.7007\n","Epoch 463/1000\n","64/64 [==============================] - 66s 1s/step - loss: 7.8383e-04 - accuracy: 0.9998 - val_loss: 2.7660 - val_accuracy: 0.6948\n","Epoch 464/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 2.8091 - val_accuracy: 0.6904\n","Epoch 465/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 2.8106 - val_accuracy: 0.6927\n","Epoch 466/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 2.7626 - val_accuracy: 0.7069\n","Epoch 467/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 2.7265 - val_accuracy: 0.7030\n","Epoch 468/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 2.6784 - val_accuracy: 0.7087\n","Epoch 469/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.8652e-04 - accuracy: 0.9998 - val_loss: 2.7725 - val_accuracy: 0.7007\n","Epoch 470/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 2.7521 - val_accuracy: 0.6956\n","Epoch 471/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.8550e-04 - accuracy: 0.9998 - val_loss: 2.7102 - val_accuracy: 0.6979\n","Epoch 472/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.7280 - val_accuracy: 0.7023\n","Epoch 473/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.7987e-04 - accuracy: 1.0000 - val_loss: 2.7770 - val_accuracy: 0.6894\n","Epoch 474/1000\n","64/64 [==============================] - 66s 1s/step - loss: 8.8169e-04 - accuracy: 0.9998 - val_loss: 2.7620 - val_accuracy: 0.6976\n","Epoch 475/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.6708 - val_accuracy: 0.7061\n","Epoch 476/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.1181e-04 - accuracy: 0.9998 - val_loss: 2.6631 - val_accuracy: 0.6987\n","Epoch 477/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0540e-04 - accuracy: 1.0000 - val_loss: 2.6701 - val_accuracy: 0.7023\n","Epoch 478/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.6824e-04 - accuracy: 0.9998 - val_loss: 2.6602 - val_accuracy: 0.7056\n","Epoch 479/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.4860e-04 - accuracy: 1.0000 - val_loss: 2.6597 - val_accuracy: 0.7064\n","Epoch 480/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.2941e-04 - accuracy: 1.0000 - val_loss: 2.6651 - val_accuracy: 0.7043\n","Epoch 481/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 2.6788 - val_accuracy: 0.7054\n","Epoch 482/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.3304e-04 - accuracy: 1.0000 - val_loss: 2.6142 - val_accuracy: 0.7092\n","Epoch 483/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.8873e-04 - accuracy: 1.0000 - val_loss: 2.7004 - val_accuracy: 0.7036\n","Epoch 484/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 2.6786 - val_accuracy: 0.7087\n","Epoch 485/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.1920e-04 - accuracy: 1.0000 - val_loss: 2.6026 - val_accuracy: 0.7159\n","Epoch 486/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.6384e-04 - accuracy: 0.9998 - val_loss: 2.7541 - val_accuracy: 0.7079\n","Epoch 487/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.7148 - val_accuracy: 0.7102\n","Epoch 488/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.4160e-04 - accuracy: 1.0000 - val_loss: 2.6692 - val_accuracy: 0.7077\n","Epoch 489/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.5719e-04 - accuracy: 0.9998 - val_loss: 2.6745 - val_accuracy: 0.7025\n","Epoch 490/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.0842e-04 - accuracy: 0.9998 - val_loss: 2.7594 - val_accuracy: 0.7131\n","Epoch 491/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 2.7361 - val_accuracy: 0.7074\n","Epoch 492/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.7774e-04 - accuracy: 1.0000 - val_loss: 2.6850 - val_accuracy: 0.7092\n","Epoch 493/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.3158e-04 - accuracy: 1.0000 - val_loss: 2.6444 - val_accuracy: 0.7131\n","Epoch 494/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 2.7242 - val_accuracy: 0.6963\n","Epoch 495/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.9118e-04 - accuracy: 1.0000 - val_loss: 2.7892 - val_accuracy: 0.6940\n","Epoch 496/1000\n","64/64 [==============================] - 66s 1s/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 2.7288 - val_accuracy: 0.7056\n","Epoch 497/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 2.7213 - val_accuracy: 0.6943\n","Epoch 498/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.1832e-04 - accuracy: 1.0000 - val_loss: 2.7238 - val_accuracy: 0.7036\n","Epoch 499/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.6065e-04 - accuracy: 0.9995 - val_loss: 2.7096 - val_accuracy: 0.7100\n","Epoch 500/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.3709e-04 - accuracy: 0.9998 - val_loss: 2.6174 - val_accuracy: 0.7092\n","Epoch 501/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.5745e-04 - accuracy: 1.0000 - val_loss: 2.6576 - val_accuracy: 0.7128\n","Epoch 502/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.5784 - val_accuracy: 0.7097\n","Epoch 503/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 2.6356 - val_accuracy: 0.6994\n","Epoch 504/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.4087e-04 - accuracy: 0.9995 - val_loss: 2.7978 - val_accuracy: 0.6909\n","Epoch 505/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 2.6875 - val_accuracy: 0.6956\n","Epoch 506/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.2886e-04 - accuracy: 0.9998 - val_loss: 2.8521 - val_accuracy: 0.6979\n","Epoch 507/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.3939e-04 - accuracy: 0.9995 - val_loss: 2.8271 - val_accuracy: 0.6909\n","Epoch 508/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.4100e-04 - accuracy: 0.9998 - val_loss: 2.7310 - val_accuracy: 0.6984\n","Epoch 509/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.9845e-04 - accuracy: 1.0000 - val_loss: 2.7486 - val_accuracy: 0.7025\n","Epoch 510/1000\n","64/64 [==============================] - 66s 1s/step - loss: 7.0252e-04 - accuracy: 1.0000 - val_loss: 2.6365 - val_accuracy: 0.7072\n","Epoch 511/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.3138e-04 - accuracy: 0.9998 - val_loss: 2.6663 - val_accuracy: 0.7005\n","Epoch 512/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.6003e-04 - accuracy: 0.9998 - val_loss: 2.5780 - val_accuracy: 0.7208\n","Epoch 513/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.6847e-04 - accuracy: 1.0000 - val_loss: 2.6775 - val_accuracy: 0.7108\n","Epoch 514/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.7471 - val_accuracy: 0.7002\n","Epoch 515/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 2.6989 - val_accuracy: 0.7041\n","Epoch 516/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 2.7310 - val_accuracy: 0.7105\n","Epoch 517/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.4440e-04 - accuracy: 1.0000 - val_loss: 2.6779 - val_accuracy: 0.7033\n","Epoch 518/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.3547e-04 - accuracy: 0.9998 - val_loss: 2.6915 - val_accuracy: 0.6958\n","Epoch 519/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.9442e-04 - accuracy: 1.0000 - val_loss: 2.7603 - val_accuracy: 0.6958\n","Epoch 520/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.0725e-04 - accuracy: 1.0000 - val_loss: 2.6672 - val_accuracy: 0.6992\n","Epoch 521/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.1701e-04 - accuracy: 0.9998 - val_loss: 2.7261 - val_accuracy: 0.7025\n","Epoch 522/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.6787 - val_accuracy: 0.7012\n","Epoch 523/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 2.7163 - val_accuracy: 0.6999\n","Epoch 524/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 2.5691 - val_accuracy: 0.7175\n","Epoch 525/1000\n","64/64 [==============================] - 66s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.5600 - val_accuracy: 0.7056\n","Epoch 526/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.8203e-04 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.6966\n","Epoch 527/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.6039 - val_accuracy: 0.6992\n","Epoch 528/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.2280e-04 - accuracy: 0.9995 - val_loss: 2.8057 - val_accuracy: 0.6951\n","Epoch 529/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.7963e-04 - accuracy: 0.9998 - val_loss: 2.7354 - val_accuracy: 0.6989\n","Epoch 530/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.8598e-04 - accuracy: 0.9998 - val_loss: 2.5927 - val_accuracy: 0.7105\n","Epoch 531/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.3094e-04 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.7038\n","Epoch 532/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2007e-04 - accuracy: 1.0000 - val_loss: 2.6056 - val_accuracy: 0.7041\n","Epoch 533/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.9940e-04 - accuracy: 1.0000 - val_loss: 2.5834 - val_accuracy: 0.7059\n","Epoch 534/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 2.6330 - val_accuracy: 0.7072\n","Epoch 535/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.3546e-04 - accuracy: 1.0000 - val_loss: 2.7187 - val_accuracy: 0.6989\n","Epoch 536/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.4958e-04 - accuracy: 1.0000 - val_loss: 2.6906 - val_accuracy: 0.6979\n","Epoch 537/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 2.5991 - val_accuracy: 0.7110\n","Epoch 538/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.6330 - val_accuracy: 0.7090\n","Epoch 539/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.1366e-04 - accuracy: 0.9998 - val_loss: 2.5208 - val_accuracy: 0.7198\n","Epoch 540/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.6326e-04 - accuracy: 0.9998 - val_loss: 2.7309 - val_accuracy: 0.7038\n","Epoch 541/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.8719e-04 - accuracy: 0.9998 - val_loss: 2.6436 - val_accuracy: 0.7007\n","Epoch 542/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.8010e-04 - accuracy: 1.0000 - val_loss: 2.6617 - val_accuracy: 0.7033\n","Epoch 543/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 2.7323 - val_accuracy: 0.6979\n","Epoch 544/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.1312e-04 - accuracy: 0.9998 - val_loss: 2.6416 - val_accuracy: 0.7087\n","Epoch 545/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.1366e-04 - accuracy: 1.0000 - val_loss: 2.6625 - val_accuracy: 0.7012\n","Epoch 546/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.7690e-04 - accuracy: 1.0000 - val_loss: 2.6694 - val_accuracy: 0.7025\n","Epoch 547/1000\n","64/64 [==============================] - 66s 1s/step - loss: 1.2979e-04 - accuracy: 1.0000 - val_loss: 2.7383 - val_accuracy: 0.7028\n","Epoch 548/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.8018e-04 - accuracy: 1.0000 - val_loss: 2.6853 - val_accuracy: 0.7010\n","Epoch 549/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.8182e-04 - accuracy: 1.0000 - val_loss: 2.6984 - val_accuracy: 0.7097\n","Epoch 550/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 2.6821 - val_accuracy: 0.6979\n","Epoch 551/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.8268e-04 - accuracy: 0.9998 - val_loss: 2.7255 - val_accuracy: 0.7077\n","Epoch 552/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.3129e-04 - accuracy: 0.9998 - val_loss: 2.6470 - val_accuracy: 0.7059\n","Epoch 553/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.4808e-04 - accuracy: 1.0000 - val_loss: 2.7646 - val_accuracy: 0.6925\n","Epoch 554/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.1689e-04 - accuracy: 0.9998 - val_loss: 2.7162 - val_accuracy: 0.6994\n","Epoch 555/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.7117 - val_accuracy: 0.7020\n","Epoch 556/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.3578e-04 - accuracy: 1.0000 - val_loss: 2.6973 - val_accuracy: 0.7017\n","Epoch 557/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.6421 - val_accuracy: 0.7059\n","Epoch 558/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.6065e-04 - accuracy: 1.0000 - val_loss: 2.7313 - val_accuracy: 0.7017\n","Epoch 559/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.4167e-04 - accuracy: 1.0000 - val_loss: 2.7469 - val_accuracy: 0.6961\n","Epoch 560/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 2.8226 - val_accuracy: 0.6917\n","Epoch 561/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.6354e-04 - accuracy: 0.9998 - val_loss: 2.7047 - val_accuracy: 0.7007\n","Epoch 562/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.1851e-04 - accuracy: 0.9998 - val_loss: 2.7068 - val_accuracy: 0.7108\n","Epoch 563/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.4459e-04 - accuracy: 1.0000 - val_loss: 2.7061 - val_accuracy: 0.7069\n","Epoch 564/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.1128e-04 - accuracy: 0.9998 - val_loss: 2.7857 - val_accuracy: 0.6922\n","Epoch 565/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 2.7344 - val_accuracy: 0.6958\n","Epoch 566/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.4916e-04 - accuracy: 0.9998 - val_loss: 2.5868 - val_accuracy: 0.7023\n","Epoch 567/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.7174e-04 - accuracy: 1.0000 - val_loss: 2.7021 - val_accuracy: 0.6999\n","Epoch 568/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.1162e-05 - accuracy: 1.0000 - val_loss: 2.8237 - val_accuracy: 0.6904\n","Epoch 569/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.5644e-04 - accuracy: 0.9998 - val_loss: 2.7344 - val_accuracy: 0.6997\n","Epoch 570/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.5206e-04 - accuracy: 1.0000 - val_loss: 2.6817 - val_accuracy: 0.7036\n","Epoch 571/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.9343e-04 - accuracy: 0.9998 - val_loss: 2.6730 - val_accuracy: 0.6935\n","Epoch 572/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.6291e-04 - accuracy: 1.0000 - val_loss: 2.7935 - val_accuracy: 0.6927\n","Epoch 573/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.0071e-04 - accuracy: 0.9995 - val_loss: 2.7236 - val_accuracy: 0.7012\n","Epoch 574/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.1599e-04 - accuracy: 0.9995 - val_loss: 2.8174 - val_accuracy: 0.6979\n","Epoch 575/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.5665e-04 - accuracy: 0.9998 - val_loss: 2.6719 - val_accuracy: 0.6999\n","Epoch 576/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.7905e-04 - accuracy: 0.9998 - val_loss: 2.7287 - val_accuracy: 0.6966\n","Epoch 577/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 2.6953 - val_accuracy: 0.7072\n","Epoch 578/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.9960e-04 - accuracy: 1.0000 - val_loss: 2.6897 - val_accuracy: 0.7059\n","Epoch 579/1000\n","64/64 [==============================] - 66s 1s/step - loss: 8.3370e-04 - accuracy: 0.9998 - val_loss: 2.7791 - val_accuracy: 0.6948\n","Epoch 580/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6828e-04 - accuracy: 1.0000 - val_loss: 2.6829 - val_accuracy: 0.7054\n","Epoch 581/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.4999e-04 - accuracy: 0.9995 - val_loss: 2.7108 - val_accuracy: 0.6999\n","Epoch 582/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.4160e-04 - accuracy: 1.0000 - val_loss: 2.6328 - val_accuracy: 0.7090\n","Epoch 583/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.4043e-04 - accuracy: 0.9998 - val_loss: 2.6724 - val_accuracy: 0.7051\n","Epoch 584/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.2819e-04 - accuracy: 1.0000 - val_loss: 2.6335 - val_accuracy: 0.7108\n","Epoch 585/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.3282e-04 - accuracy: 0.9998 - val_loss: 2.8271 - val_accuracy: 0.7025\n","Epoch 586/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.6588e-05 - accuracy: 1.0000 - val_loss: 2.8143 - val_accuracy: 0.7007\n","Epoch 587/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.6524e-04 - accuracy: 1.0000 - val_loss: 2.8454 - val_accuracy: 0.7113\n","Epoch 588/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.7571e-04 - accuracy: 0.9998 - val_loss: 2.7617 - val_accuracy: 0.6953\n","Epoch 589/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.3280e-04 - accuracy: 1.0000 - val_loss: 2.8252 - val_accuracy: 0.6969\n","Epoch 590/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.8264e-04 - accuracy: 1.0000 - val_loss: 2.7519 - val_accuracy: 0.6932\n","Epoch 591/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.4827e-04 - accuracy: 1.0000 - val_loss: 2.7463 - val_accuracy: 0.6956\n","Epoch 592/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.5285e-04 - accuracy: 1.0000 - val_loss: 2.6561 - val_accuracy: 0.7010\n","Epoch 593/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.5991e-04 - accuracy: 0.9998 - val_loss: 2.7665 - val_accuracy: 0.6979\n","Epoch 594/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.5267e-04 - accuracy: 0.9998 - val_loss: 2.8091 - val_accuracy: 0.6961\n","Epoch 595/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.5898e-04 - accuracy: 0.9998 - val_loss: 2.6557 - val_accuracy: 0.7123\n","Epoch 596/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.8203e-05 - accuracy: 1.0000 - val_loss: 2.6808 - val_accuracy: 0.7082\n","Epoch 597/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.1748e-04 - accuracy: 0.9998 - val_loss: 2.7803 - val_accuracy: 0.7048\n","Epoch 598/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.8956e-04 - accuracy: 1.0000 - val_loss: 2.8931 - val_accuracy: 0.6969\n","Epoch 599/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 2.7168 - val_accuracy: 0.7007\n","Epoch 600/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.6905e-04 - accuracy: 0.9998 - val_loss: 2.6792 - val_accuracy: 0.7077\n","Epoch 601/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.1905e-04 - accuracy: 1.0000 - val_loss: 2.6762 - val_accuracy: 0.7012\n","Epoch 602/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.2567e-04 - accuracy: 1.0000 - val_loss: 2.5652 - val_accuracy: 0.7152\n","Epoch 603/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 2.8706 - val_accuracy: 0.6953\n","Epoch 604/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.9480e-04 - accuracy: 0.9998 - val_loss: 2.7883 - val_accuracy: 0.6992\n","Epoch 605/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.3044e-04 - accuracy: 1.0000 - val_loss: 2.6829 - val_accuracy: 0.7043\n","Epoch 606/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.7999e-04 - accuracy: 1.0000 - val_loss: 2.7679 - val_accuracy: 0.7015\n","Epoch 607/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2256e-04 - accuracy: 1.0000 - val_loss: 2.7324 - val_accuracy: 0.7028\n","Epoch 608/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.8043e-04 - accuracy: 0.9995 - val_loss: 2.8506 - val_accuracy: 0.6992\n","Epoch 609/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.6598e-05 - accuracy: 1.0000 - val_loss: 2.7623 - val_accuracy: 0.7084\n","Epoch 610/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.8648e-04 - accuracy: 1.0000 - val_loss: 2.7426 - val_accuracy: 0.7082\n","Epoch 611/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.8426e-04 - accuracy: 0.9995 - val_loss: 2.8284 - val_accuracy: 0.6950\n","Epoch 612/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 2.7255 - val_accuracy: 0.7043\n","Epoch 613/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2433e-04 - accuracy: 1.0000 - val_loss: 2.6678 - val_accuracy: 0.7061\n","Epoch 614/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.1124e-04 - accuracy: 1.0000 - val_loss: 2.7275 - val_accuracy: 0.7069\n","Epoch 615/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.8831e-04 - accuracy: 0.9995 - val_loss: 2.6997 - val_accuracy: 0.7033\n","Epoch 616/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 2.6734 - val_accuracy: 0.7017\n","Epoch 617/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.0029e-04 - accuracy: 0.9998 - val_loss: 2.7449 - val_accuracy: 0.7128\n","Epoch 618/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.6914e-04 - accuracy: 0.9998 - val_loss: 2.7240 - val_accuracy: 0.7036\n","Epoch 619/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.2012e-04 - accuracy: 0.9998 - val_loss: 2.7716 - val_accuracy: 0.7015\n","Epoch 620/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.0955e-04 - accuracy: 1.0000 - val_loss: 2.8190 - val_accuracy: 0.7033\n","Epoch 621/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.7305e-04 - accuracy: 1.0000 - val_loss: 2.7606 - val_accuracy: 0.7048\n","Epoch 622/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.2449e-04 - accuracy: 1.0000 - val_loss: 2.8093 - val_accuracy: 0.7002\n","Epoch 623/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 2.6861 - val_accuracy: 0.7020\n","Epoch 624/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.2792e-04 - accuracy: 1.0000 - val_loss: 2.6871 - val_accuracy: 0.7084\n","Epoch 625/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.7578 - val_accuracy: 0.7028\n","Epoch 626/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 2.6565 - val_accuracy: 0.7100\n","Epoch 627/1000\n","64/64 [==============================] - 66s 1s/step - loss: 2.7722e-04 - accuracy: 1.0000 - val_loss: 2.7986 - val_accuracy: 0.6989\n","Epoch 628/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.6613e-04 - accuracy: 1.0000 - val_loss: 2.7744 - val_accuracy: 0.6951\n","Epoch 629/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.9927e-04 - accuracy: 0.9995 - val_loss: 2.8441 - val_accuracy: 0.6958\n","Epoch 630/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.8871e-04 - accuracy: 0.9998 - val_loss: 2.8617 - val_accuracy: 0.6987\n","Epoch 631/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.9142e-04 - accuracy: 1.0000 - val_loss: 2.7874 - val_accuracy: 0.7115\n","Epoch 632/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 2.7704 - val_accuracy: 0.6956\n","Epoch 633/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.4361e-04 - accuracy: 0.9998 - val_loss: 2.7336 - val_accuracy: 0.7038\n","Epoch 634/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.8499e-04 - accuracy: 0.9998 - val_loss: 2.6407 - val_accuracy: 0.7054\n","Epoch 635/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.1449e-04 - accuracy: 1.0000 - val_loss: 2.7444 - val_accuracy: 0.6958\n","Epoch 636/1000\n","64/64 [==============================] - 66s 1s/step - loss: 6.3334e-04 - accuracy: 0.9998 - val_loss: 2.8325 - val_accuracy: 0.6933\n","Epoch 637/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.1282e-04 - accuracy: 0.9998 - val_loss: 2.6214 - val_accuracy: 0.7105\n","Epoch 638/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2854e-04 - accuracy: 1.0000 - val_loss: 2.7943 - val_accuracy: 0.6927\n","Epoch 639/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.4486e-04 - accuracy: 0.9998 - val_loss: 2.6900 - val_accuracy: 0.7020\n","Epoch 640/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.7232e-04 - accuracy: 0.9995 - val_loss: 2.6624 - val_accuracy: 0.7092\n","Epoch 641/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.0660e-04 - accuracy: 0.9998 - val_loss: 2.7666 - val_accuracy: 0.7007\n","Epoch 642/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.1647e-04 - accuracy: 1.0000 - val_loss: 2.7773 - val_accuracy: 0.7054\n","Epoch 643/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.1478e-04 - accuracy: 1.0000 - val_loss: 2.7900 - val_accuracy: 0.7007\n","Epoch 644/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.8832e-05 - accuracy: 1.0000 - val_loss: 2.7521 - val_accuracy: 0.6994\n","Epoch 645/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.7758e-04 - accuracy: 0.9998 - val_loss: 2.7908 - val_accuracy: 0.6948\n","Epoch 646/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.7449 - val_accuracy: 0.7105\n","Epoch 647/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.3577e-04 - accuracy: 1.0000 - val_loss: 2.8051 - val_accuracy: 0.7002\n","Epoch 648/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.1882e-04 - accuracy: 0.9998 - val_loss: 2.7089 - val_accuracy: 0.7020\n","Epoch 649/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.7347e-04 - accuracy: 1.0000 - val_loss: 2.7267 - val_accuracy: 0.6961\n","Epoch 650/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.1070e-04 - accuracy: 0.9995 - val_loss: 2.8538 - val_accuracy: 0.6984\n","Epoch 651/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.3304e-04 - accuracy: 1.0000 - val_loss: 2.7287 - val_accuracy: 0.7038\n","Epoch 652/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.6319 - val_accuracy: 0.7090\n","Epoch 653/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.3668e-04 - accuracy: 0.9998 - val_loss: 2.7920 - val_accuracy: 0.7059\n","Epoch 654/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2489e-04 - accuracy: 1.0000 - val_loss: 2.7653 - val_accuracy: 0.7023\n","Epoch 655/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.3278e-04 - accuracy: 1.0000 - val_loss: 2.7459 - val_accuracy: 0.7072\n","Epoch 656/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.3037e-04 - accuracy: 1.0000 - val_loss: 2.7444 - val_accuracy: 0.7054\n","Epoch 657/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.5398e-04 - accuracy: 1.0000 - val_loss: 2.6882 - val_accuracy: 0.7051\n","Epoch 658/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.1325e-05 - accuracy: 1.0000 - val_loss: 2.7140 - val_accuracy: 0.7036\n","Epoch 659/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.5821e-04 - accuracy: 1.0000 - val_loss: 2.8979 - val_accuracy: 0.6945\n","Epoch 660/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.5998e-04 - accuracy: 1.0000 - val_loss: 2.7337 - val_accuracy: 0.7041\n","Epoch 661/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.7270 - val_accuracy: 0.7015\n","Epoch 662/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 2.7941 - val_accuracy: 0.6950\n","Epoch 663/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0098e-04 - accuracy: 1.0000 - val_loss: 2.7300 - val_accuracy: 0.7059\n","Epoch 664/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.4977e-04 - accuracy: 0.9995 - val_loss: 2.7351 - val_accuracy: 0.7056\n","Epoch 665/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.1930e-04 - accuracy: 1.0000 - val_loss: 2.7591 - val_accuracy: 0.7012\n","Epoch 666/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.8683e-04 - accuracy: 1.0000 - val_loss: 2.6982 - val_accuracy: 0.7074\n","Epoch 667/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6711e-04 - accuracy: 1.0000 - val_loss: 2.7561 - val_accuracy: 0.6922\n","Epoch 668/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.5400e-04 - accuracy: 0.9998 - val_loss: 2.6861 - val_accuracy: 0.7136\n","Epoch 669/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.9398e-04 - accuracy: 1.0000 - val_loss: 2.6452 - val_accuracy: 0.7113\n","Epoch 670/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.3119e-04 - accuracy: 0.9998 - val_loss: 2.7248 - val_accuracy: 0.6963\n","Epoch 671/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.4095e-04 - accuracy: 1.0000 - val_loss: 2.7526 - val_accuracy: 0.7028\n","Epoch 672/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.1267e-04 - accuracy: 1.0000 - val_loss: 2.7429 - val_accuracy: 0.7015\n","Epoch 673/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6374e-04 - accuracy: 1.0000 - val_loss: 2.7847 - val_accuracy: 0.6997\n","Epoch 674/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.7467e-05 - accuracy: 1.0000 - val_loss: 2.6273 - val_accuracy: 0.6979\n","Epoch 675/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 2.7179 - val_accuracy: 0.7069\n","Epoch 676/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 2.7524 - val_accuracy: 0.6951\n","Epoch 677/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.2706e-04 - accuracy: 1.0000 - val_loss: 2.6776 - val_accuracy: 0.7059\n","Epoch 678/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.7090e-04 - accuracy: 1.0000 - val_loss: 2.5546 - val_accuracy: 0.7146\n","Epoch 679/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 2.7589 - val_accuracy: 0.6920\n","Epoch 680/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.7911 - val_accuracy: 0.7108\n","Epoch 681/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.9747e-04 - accuracy: 0.9998 - val_loss: 2.7306 - val_accuracy: 0.7010\n","Epoch 682/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.3467e-04 - accuracy: 0.9998 - val_loss: 2.7098 - val_accuracy: 0.7038\n","Epoch 683/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.1806e-04 - accuracy: 0.9998 - val_loss: 2.8001 - val_accuracy: 0.6981\n","Epoch 684/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 2.7642 - val_accuracy: 0.7048\n","Epoch 685/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.5103e-04 - accuracy: 0.9998 - val_loss: 2.6684 - val_accuracy: 0.7102\n","Epoch 686/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.5914e-04 - accuracy: 0.9998 - val_loss: 2.7684 - val_accuracy: 0.7007\n","Epoch 687/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.3181e-04 - accuracy: 1.0000 - val_loss: 2.6987 - val_accuracy: 0.7087\n","Epoch 688/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.1970e-04 - accuracy: 1.0000 - val_loss: 2.7513 - val_accuracy: 0.7017\n","Epoch 689/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.6133e-04 - accuracy: 1.0000 - val_loss: 2.7147 - val_accuracy: 0.7069\n","Epoch 690/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.6139e-04 - accuracy: 0.9998 - val_loss: 2.7537 - val_accuracy: 0.6999\n","Epoch 691/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.7783e-04 - accuracy: 0.9998 - val_loss: 2.7048 - val_accuracy: 0.7126\n","Epoch 692/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6226e-04 - accuracy: 1.0000 - val_loss: 2.7887 - val_accuracy: 0.7023\n","Epoch 693/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.4462e-04 - accuracy: 0.9998 - val_loss: 2.7719 - val_accuracy: 0.7123\n","Epoch 694/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 2.7847 - val_accuracy: 0.7020\n","Epoch 695/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.0260e-04 - accuracy: 0.9998 - val_loss: 2.7529 - val_accuracy: 0.7018\n","Epoch 696/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.4571e-04 - accuracy: 1.0000 - val_loss: 2.7359 - val_accuracy: 0.7046\n","Epoch 697/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 2.8229 - val_accuracy: 0.6974\n","Epoch 698/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.1794e-04 - accuracy: 0.9998 - val_loss: 2.7412 - val_accuracy: 0.7046\n","Epoch 699/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.2604e-04 - accuracy: 1.0000 - val_loss: 2.8080 - val_accuracy: 0.6974\n","Epoch 700/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.5514e-04 - accuracy: 0.9998 - val_loss: 2.6812 - val_accuracy: 0.7108\n","Epoch 701/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.4620e-05 - accuracy: 1.0000 - val_loss: 2.7294 - val_accuracy: 0.7092\n","Epoch 702/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.2069e-04 - accuracy: 0.9998 - val_loss: 2.6559 - val_accuracy: 0.7066\n","Epoch 703/1000\n","64/64 [==============================] - 66s 1s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.8185 - val_accuracy: 0.7030\n","Epoch 704/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.4109e-04 - accuracy: 0.9998 - val_loss: 2.7135 - val_accuracy: 0.7043\n","Epoch 705/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.3103e-04 - accuracy: 0.9998 - val_loss: 2.6731 - val_accuracy: 0.7162\n","Epoch 706/1000\n","64/64 [==============================] - 66s 1s/step - loss: 3.8557e-04 - accuracy: 1.0000 - val_loss: 2.7775 - val_accuracy: 0.6987\n","Epoch 707/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.9746e-04 - accuracy: 0.9995 - val_loss: 2.8901 - val_accuracy: 0.6958\n","Epoch 708/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.7434 - val_accuracy: 0.7036\n","Epoch 709/1000\n","64/64 [==============================] - 66s 1s/step - loss: 3.4376e-04 - accuracy: 1.0000 - val_loss: 2.7422 - val_accuracy: 0.7084\n","Epoch 710/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.9746e-04 - accuracy: 1.0000 - val_loss: 2.7701 - val_accuracy: 0.7005\n","Epoch 711/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.2702e-04 - accuracy: 1.0000 - val_loss: 2.7063 - val_accuracy: 0.7048\n","Epoch 712/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.5576e-04 - accuracy: 0.9995 - val_loss: 2.7307 - val_accuracy: 0.7041\n","Epoch 713/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.8041 - val_accuracy: 0.7012\n","Epoch 714/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.5067e-05 - accuracy: 1.0000 - val_loss: 2.7462 - val_accuracy: 0.7082\n","Epoch 715/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.0538e-04 - accuracy: 0.9998 - val_loss: 2.6443 - val_accuracy: 0.7110\n","Epoch 716/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.3216e-04 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.7079\n","Epoch 717/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 2.7465 - val_accuracy: 0.7072\n","Epoch 718/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.7328 - val_accuracy: 0.7120\n","Epoch 719/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.2150e-05 - accuracy: 1.0000 - val_loss: 2.6347 - val_accuracy: 0.7098\n","Epoch 720/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.9181e-04 - accuracy: 1.0000 - val_loss: 2.6910 - val_accuracy: 0.7033\n","Epoch 721/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.2423e-04 - accuracy: 1.0000 - val_loss: 2.6567 - val_accuracy: 0.7118\n","Epoch 722/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.5857e-04 - accuracy: 1.0000 - val_loss: 2.7211 - val_accuracy: 0.7079\n","Epoch 723/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.4601e-04 - accuracy: 1.0000 - val_loss: 2.8194 - val_accuracy: 0.6994\n","Epoch 724/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.8114 - val_accuracy: 0.6971\n","Epoch 725/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 2.7804 - val_accuracy: 0.6981\n","Epoch 726/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.3992e-05 - accuracy: 1.0000 - val_loss: 2.6392 - val_accuracy: 0.7095\n","Epoch 727/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.3706e-04 - accuracy: 0.9998 - val_loss: 2.8176 - val_accuracy: 0.7118\n","Epoch 728/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.8640e-05 - accuracy: 1.0000 - val_loss: 2.8419 - val_accuracy: 0.6997\n","Epoch 729/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0901e-04 - accuracy: 1.0000 - val_loss: 2.7911 - val_accuracy: 0.7010\n","Epoch 730/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0338e-04 - accuracy: 1.0000 - val_loss: 2.7300 - val_accuracy: 0.7012\n","Epoch 731/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.5593e-04 - accuracy: 0.9998 - val_loss: 2.7695 - val_accuracy: 0.7087\n","Epoch 732/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 2.7463 - val_accuracy: 0.6981\n","Epoch 733/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.7624e-04 - accuracy: 0.9998 - val_loss: 2.7174 - val_accuracy: 0.7064\n","Epoch 734/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.8453e-04 - accuracy: 0.9995 - val_loss: 2.7217 - val_accuracy: 0.7105\n","Epoch 735/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.1841e-04 - accuracy: 0.9998 - val_loss: 2.7040 - val_accuracy: 0.7154\n","Epoch 736/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.8321e-04 - accuracy: 0.9995 - val_loss: 2.7630 - val_accuracy: 0.7136\n","Epoch 737/1000\n","64/64 [==============================] - 66s 1s/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 2.8043 - val_accuracy: 0.6989\n","Epoch 738/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.3986e-04 - accuracy: 1.0000 - val_loss: 2.7451 - val_accuracy: 0.7102\n","Epoch 739/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.8791e-04 - accuracy: 0.9995 - val_loss: 2.7717 - val_accuracy: 0.7012\n","Epoch 740/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.5007e-04 - accuracy: 0.9995 - val_loss: 2.8797 - val_accuracy: 0.6945\n","Epoch 741/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.0328e-04 - accuracy: 0.9998 - val_loss: 2.7770 - val_accuracy: 0.7043\n","Epoch 742/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.5441e-04 - accuracy: 1.0000 - val_loss: 2.7761 - val_accuracy: 0.7048\n","Epoch 743/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.8955e-04 - accuracy: 0.9998 - val_loss: 2.7517 - val_accuracy: 0.7059\n","Epoch 744/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.6688e-04 - accuracy: 1.0000 - val_loss: 2.7845 - val_accuracy: 0.7102\n","Epoch 745/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.7350 - val_accuracy: 0.7048\n","Epoch 746/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.2868e-04 - accuracy: 0.9998 - val_loss: 2.7599 - val_accuracy: 0.7074\n","Epoch 747/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6553e-04 - accuracy: 1.0000 - val_loss: 2.8396 - val_accuracy: 0.6976\n","Epoch 748/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.0019e-04 - accuracy: 1.0000 - val_loss: 2.7037 - val_accuracy: 0.7061\n","Epoch 749/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.8289e-04 - accuracy: 1.0000 - val_loss: 2.7402 - val_accuracy: 0.7033\n","Epoch 750/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.7209e-04 - accuracy: 0.9998 - val_loss: 2.7581 - val_accuracy: 0.7066\n","Epoch 751/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2566e-04 - accuracy: 1.0000 - val_loss: 2.7903 - val_accuracy: 0.7087\n","Epoch 752/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 2.8353 - val_accuracy: 0.6979\n","Epoch 753/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0078e-04 - accuracy: 1.0000 - val_loss: 2.6938 - val_accuracy: 0.7118\n","Epoch 754/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.1083e-04 - accuracy: 1.0000 - val_loss: 2.7427 - val_accuracy: 0.7064\n","Epoch 755/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 2.8001 - val_accuracy: 0.7010\n","Epoch 756/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.7611 - val_accuracy: 0.7056\n","Epoch 757/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.2468e-04 - accuracy: 0.9998 - val_loss: 2.8168 - val_accuracy: 0.7017\n","Epoch 758/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.0542e-04 - accuracy: 1.0000 - val_loss: 2.7771 - val_accuracy: 0.7105\n","Epoch 759/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.9656e-04 - accuracy: 1.0000 - val_loss: 2.7579 - val_accuracy: 0.7015\n","Epoch 760/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.6144e-04 - accuracy: 0.9998 - val_loss: 2.7711 - val_accuracy: 0.7061\n","Epoch 761/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.6899e-04 - accuracy: 0.9998 - val_loss: 2.6573 - val_accuracy: 0.7131\n","Epoch 762/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.9478e-04 - accuracy: 1.0000 - val_loss: 2.8613 - val_accuracy: 0.7038\n","Epoch 763/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.4776e-04 - accuracy: 0.9995 - val_loss: 2.7668 - val_accuracy: 0.7010\n","Epoch 764/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.6667e-04 - accuracy: 0.9995 - val_loss: 2.8122 - val_accuracy: 0.7002\n","Epoch 765/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.3898e-04 - accuracy: 0.9995 - val_loss: 2.7151 - val_accuracy: 0.7115\n","Epoch 766/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 2.7357 - val_accuracy: 0.7077\n","Epoch 767/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.8753e-04 - accuracy: 1.0000 - val_loss: 2.7980 - val_accuracy: 0.7059\n","Epoch 768/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.4739e-04 - accuracy: 1.0000 - val_loss: 2.7729 - val_accuracy: 0.6981\n","Epoch 769/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 2.7713 - val_accuracy: 0.7048\n","Epoch 770/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.3840e-04 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.7041\n","Epoch 771/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 2.6854 - val_accuracy: 0.7123\n","Epoch 772/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.4279e-04 - accuracy: 0.9998 - val_loss: 2.7513 - val_accuracy: 0.7036\n","Epoch 773/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.0683e-04 - accuracy: 1.0000 - val_loss: 2.7857 - val_accuracy: 0.7049\n","Epoch 774/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.2894e-04 - accuracy: 1.0000 - val_loss: 2.7630 - val_accuracy: 0.7072\n","Epoch 775/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.1172e-04 - accuracy: 1.0000 - val_loss: 2.6678 - val_accuracy: 0.7036\n","Epoch 776/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.0200e-05 - accuracy: 1.0000 - val_loss: 2.7543 - val_accuracy: 0.7012\n","Epoch 777/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.6456e-04 - accuracy: 1.0000 - val_loss: 2.6902 - val_accuracy: 0.7051\n","Epoch 778/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.8862e-05 - accuracy: 1.0000 - val_loss: 2.7244 - val_accuracy: 0.7105\n","Epoch 779/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.7586e-04 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.7121\n","Epoch 780/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.0535e-04 - accuracy: 0.9998 - val_loss: 2.7944 - val_accuracy: 0.7072\n","Epoch 781/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.4598e-04 - accuracy: 1.0000 - val_loss: 2.7132 - val_accuracy: 0.7079\n","Epoch 782/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.8149e-04 - accuracy: 1.0000 - val_loss: 2.7737 - val_accuracy: 0.7051\n","Epoch 783/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.4120e-05 - accuracy: 1.0000 - val_loss: 2.8151 - val_accuracy: 0.7079\n","Epoch 784/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.3066e-04 - accuracy: 0.9998 - val_loss: 2.7790 - val_accuracy: 0.7074\n","Epoch 785/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 2.7896 - val_accuracy: 0.7059\n","Epoch 786/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.4229e-04 - accuracy: 0.9995 - val_loss: 2.6601 - val_accuracy: 0.7084\n","Epoch 787/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.3999e-04 - accuracy: 0.9998 - val_loss: 2.7621 - val_accuracy: 0.7038\n","Epoch 788/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.2503e-04 - accuracy: 1.0000 - val_loss: 2.7909 - val_accuracy: 0.7049\n","Epoch 789/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.7775e-04 - accuracy: 1.0000 - val_loss: 2.8088 - val_accuracy: 0.7033\n","Epoch 790/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.1724e-04 - accuracy: 1.0000 - val_loss: 2.7311 - val_accuracy: 0.7056\n","Epoch 791/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.7456e-04 - accuracy: 0.9998 - val_loss: 2.7800 - val_accuracy: 0.7090\n","Epoch 792/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.9118e-04 - accuracy: 0.9998 - val_loss: 2.6634 - val_accuracy: 0.7051\n","Epoch 793/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.4451e-05 - accuracy: 1.0000 - val_loss: 2.7393 - val_accuracy: 0.7051\n","Epoch 794/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.6834e-04 - accuracy: 0.9998 - val_loss: 2.7392 - val_accuracy: 0.6958\n","Epoch 795/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.6674e-04 - accuracy: 0.9995 - val_loss: 2.7346 - val_accuracy: 0.7072\n","Epoch 796/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.1322e-04 - accuracy: 1.0000 - val_loss: 2.8381 - val_accuracy: 0.6958\n","Epoch 797/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.2341e-04 - accuracy: 1.0000 - val_loss: 2.7699 - val_accuracy: 0.7059\n","Epoch 798/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.7769e-04 - accuracy: 0.9998 - val_loss: 2.7797 - val_accuracy: 0.7079\n","Epoch 799/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.8205e-04 - accuracy: 1.0000 - val_loss: 2.7761 - val_accuracy: 0.7090\n","Epoch 800/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.0200e-04 - accuracy: 1.0000 - val_loss: 2.8118 - val_accuracy: 0.6992\n","Epoch 801/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.0312e-04 - accuracy: 0.9998 - val_loss: 2.7368 - val_accuracy: 0.7017\n","Epoch 802/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.9956e-04 - accuracy: 0.9998 - val_loss: 2.8323 - val_accuracy: 0.7002\n","Epoch 803/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.0629e-04 - accuracy: 0.9998 - val_loss: 2.7785 - val_accuracy: 0.7165\n","Epoch 804/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.2472e-04 - accuracy: 0.9998 - val_loss: 2.7386 - val_accuracy: 0.7136\n","Epoch 805/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.4834e-04 - accuracy: 1.0000 - val_loss: 2.7255 - val_accuracy: 0.7149\n","Epoch 806/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6511e-04 - accuracy: 1.0000 - val_loss: 2.7495 - val_accuracy: 0.7043\n","Epoch 807/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 2.7864 - val_accuracy: 0.6953\n","Epoch 808/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.3840e-04 - accuracy: 0.9998 - val_loss: 2.6899 - val_accuracy: 0.7030\n","Epoch 809/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.2292e-05 - accuracy: 1.0000 - val_loss: 2.7173 - val_accuracy: 0.7090\n","Epoch 810/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 2.7218 - val_accuracy: 0.7051\n","Epoch 811/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.7233e-05 - accuracy: 1.0000 - val_loss: 2.7114 - val_accuracy: 0.7092\n","Epoch 812/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.0230e-05 - accuracy: 1.0000 - val_loss: 2.8085 - val_accuracy: 0.7028\n","Epoch 813/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.3225e-04 - accuracy: 1.0000 - val_loss: 2.6863 - val_accuracy: 0.7069\n","Epoch 814/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2902e-04 - accuracy: 1.0000 - val_loss: 2.7557 - val_accuracy: 0.7072\n","Epoch 815/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.6238e-04 - accuracy: 0.9998 - val_loss: 2.6809 - val_accuracy: 0.7087\n","Epoch 816/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.0844e-04 - accuracy: 1.0000 - val_loss: 2.7511 - val_accuracy: 0.7017\n","Epoch 817/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.3907e-04 - accuracy: 1.0000 - val_loss: 2.7889 - val_accuracy: 0.6989\n","Epoch 818/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 2.7381 - val_accuracy: 0.7038\n","Epoch 819/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.9425e-05 - accuracy: 1.0000 - val_loss: 2.8634 - val_accuracy: 0.6935\n","Epoch 820/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0581e-04 - accuracy: 1.0000 - val_loss: 2.7661 - val_accuracy: 0.6994\n","Epoch 821/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.2413e-05 - accuracy: 1.0000 - val_loss: 2.7555 - val_accuracy: 0.7056\n","Epoch 822/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.7825e-04 - accuracy: 1.0000 - val_loss: 2.7264 - val_accuracy: 0.7074\n","Epoch 823/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.1368e-04 - accuracy: 1.0000 - val_loss: 2.7412 - val_accuracy: 0.7069\n","Epoch 824/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.2237e-04 - accuracy: 1.0000 - val_loss: 2.8151 - val_accuracy: 0.7064\n","Epoch 825/1000\n","64/64 [==============================] - 65s 1s/step - loss: 8.8730e-04 - accuracy: 0.9995 - val_loss: 2.6857 - val_accuracy: 0.7074\n","Epoch 826/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.0219e-04 - accuracy: 1.0000 - val_loss: 2.7615 - val_accuracy: 0.7023\n","Epoch 827/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.6667e-04 - accuracy: 1.0000 - val_loss: 2.7176 - val_accuracy: 0.7018\n","Epoch 828/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.0247e-04 - accuracy: 0.9998 - val_loss: 2.6558 - val_accuracy: 0.7156\n","Epoch 829/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.7222e-04 - accuracy: 0.9998 - val_loss: 2.7905 - val_accuracy: 0.7025\n","Epoch 830/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0570e-04 - accuracy: 1.0000 - val_loss: 2.7666 - val_accuracy: 0.7059\n","Epoch 831/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.0401e-04 - accuracy: 1.0000 - val_loss: 2.7949 - val_accuracy: 0.7005\n","Epoch 832/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.7974e-04 - accuracy: 1.0000 - val_loss: 2.7717 - val_accuracy: 0.7074\n","Epoch 833/1000\n","64/64 [==============================] - 65s 1s/step - loss: 5.3777e-04 - accuracy: 0.9998 - val_loss: 2.6845 - val_accuracy: 0.7154\n","Epoch 834/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.9698e-04 - accuracy: 0.9998 - val_loss: 2.8247 - val_accuracy: 0.7025\n","Epoch 835/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.8879e-04 - accuracy: 0.9998 - val_loss: 2.7427 - val_accuracy: 0.7066\n","Epoch 836/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.7436e-04 - accuracy: 1.0000 - val_loss: 2.7661 - val_accuracy: 0.7154\n","Epoch 837/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.0718e-04 - accuracy: 1.0000 - val_loss: 2.8190 - val_accuracy: 0.7064\n","Epoch 838/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.7844 - val_accuracy: 0.7059\n","Epoch 839/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 2.6481 - val_accuracy: 0.7128\n","Epoch 840/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.7638 - val_accuracy: 0.7069\n","Epoch 841/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.1098e-05 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.7020\n","Epoch 842/1000\n","64/64 [==============================] - 65s 1s/step - loss: 1.5070e-04 - accuracy: 1.0000 - val_loss: 2.7198 - val_accuracy: 0.7020\n","Epoch 843/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.1642e-04 - accuracy: 1.0000 - val_loss: 2.6708 - val_accuracy: 0.7131\n","Epoch 844/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.1261e-04 - accuracy: 0.9998 - val_loss: 2.7454 - val_accuracy: 0.7115\n","Epoch 845/1000\n","64/64 [==============================] - 65s 1s/step - loss: 7.4928e-05 - accuracy: 1.0000 - val_loss: 2.8583 - val_accuracy: 0.7023\n","Epoch 846/1000\n","64/64 [==============================] - 65s 1s/step - loss: 4.3577e-04 - accuracy: 0.9998 - val_loss: 2.8227 - val_accuracy: 0.7105\n","Epoch 847/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.5918e-04 - accuracy: 1.0000 - val_loss: 2.6740 - val_accuracy: 0.7100\n","Epoch 848/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.7327 - val_accuracy: 0.7012\n","Epoch 849/1000\n","64/64 [==============================] - 65s 1s/step - loss: 9.8770e-05 - accuracy: 1.0000 - val_loss: 2.7711 - val_accuracy: 0.7025\n","Epoch 850/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.7014e-04 - accuracy: 1.0000 - val_loss: 2.7955 - val_accuracy: 0.7048\n","Epoch 851/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 2.7479 - val_accuracy: 0.7059\n","Epoch 852/1000\n","64/64 [==============================] - 65s 1s/step - loss: 3.8847e-04 - accuracy: 0.9998 - val_loss: 2.7688 - val_accuracy: 0.7010\n","Epoch 853/1000\n","64/64 [==============================] - 65s 1s/step - loss: 6.5762e-04 - accuracy: 1.0000 - val_loss: 2.7334 - val_accuracy: 0.7082\n","Epoch 854/1000\n","64/64 [==============================] - 65s 1s/step - loss: 2.2929e-04 - accuracy: 1.0000 - val_loss: 2.7302 - val_accuracy: 0.7100\n","Epoch 855/1000\n","64/64 [==============================] - 65s 1s/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 2.8089 - val_accuracy: 0.6984\n","Epoch 856/1000\n"," 1/64 [..............................] - ETA: 48s - loss: 5.4683e-06 - accuracy: 1.0000"]}],"source":["# Create the image generator\n","datagen = ImageDataGenerator(featurewise_std_normalization=True)\n","train_batches = datagen.flow(train_x, train_y, batch_size=64)\n","train_crops = utils.crop_generator(train_batches, 224)\n","val_batches = datagen.flow(val_x, val_y, batch_size=64)\n","val_crops = utils.crop_generator(val_batches, 224)\n","test_batches = datagen.flow(test_x, test_y, batch_size=1, shuffle=False)\n","test_crops = utils.crop_generator(test_batches, 224)\n","\n","history = model.fit_generator(train_crops, epochs=1000, steps_per_epoch=64,\n","                                       validation_data=val_crops, validation_steps=64)\n","\n","print(history.history)"]},{"cell_type":"markdown","source":["# Plot history"],"metadata":{"id":"i6wxmintsLSl"},"id":"i6wxmintsLSl"},{"cell_type":"code","source":["df_loss_acc = pd.DataFrame(history.history)\n","df_loss = df_loss_acc[['loss', 'val_loss']]\n","df_acc = df_loss_acc[['accuracy', 'val_accuracy']]\n","df_loss.plot(title='Model loss', figsize=(12, 8)).set(xlabel='Epoch', ylabel='Loss')\n","df_acc.plot(title='Model Accuracy', figsize=(12, 8)).set(xlabel='Epoch', ylabel='Accuracy')\n","plt.show()"],"metadata":{"id":"zhTiVHnisPW8"},"id":"zhTiVHnisPW8","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"5c270c0b","metadata":{"id":"5c270c0b"},"source":["# Test the model"]},{"cell_type":"code","execution_count":null,"id":"73ea11eb","metadata":{"id":"73ea11eb"},"outputs":[],"source":["temp_x, y = [], []\n","x = np.empty((1000, 224, 224, 3))\n","for i in range(1000):\n","    a, b = test_crops.__next__()\n","    temp_x.extend(a)\n","    x[i,] = a\n","    y.extend(b)\n","print(x.shape)\n","Pred_y = model.predict(x)\n","pred_y = np.argmax(Pred_y, axis=1)\n","Test_y = np.array(y)\n","test_y = np.argmax(Test_y, axis=1)\n","print(test_y)\n","print('pred_y')\n","print(pred_y)\n","# Calculate accuracy, precision, recall and confusion matrix\n","print('Test Accuracy: ', accuracy_score(test_y, pred_y))\n","print('Test Precision: ', precision_score(test_y, pred_y, zero_division=0, average='weighted'))\n","print('Test Recall: ', recall_score(test_y, pred_y, average='weighted'))\n","print('Test f1', f1_score(test_y, pred_y, zero_division=0, average='weighted', labels=np.unique(pred_y)))\n"]},{"cell_type":"markdown","source":["# Confusion Matrix"],"metadata":{"id":"1KaxWlUptUCv"},"id":"1KaxWlUptUCv"},{"cell_type":"code","source":["cm = confusion_matrix(test_y, pred_y)\n","print('Confusion Matrix')\n","print(cm)\n","cmd = ConfusionMatrixDisplay(confusion_matrix=cm)\n","cmd.plot()\n","plt.show()"],"metadata":{"id":"y3nZbQgttWoh"},"id":"y3nZbQgttWoh","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Calculate the scores"],"metadata":{"id":"n--zQSdrpG2b"},"id":"n--zQSdrpG2b"},{"cell_type":"code","source":["scores = model.evaluate(test_crops, steps=1000)\n","print(scores)"],"metadata":{"id":"DzXjbTXSpE0F"},"id":"DzXjbTXSpE0F","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"resnet.ipynb","provenance":[],"collapsed_sections":["gJ6Nryd_1NrE"],"machine_shape":"hm","background_execution":"on"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}